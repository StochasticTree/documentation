{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Tree Inspection\n",
    "\n",
    "While out of sample evaluation and MCMC diagnostics on parametric BART components (i.e. $\\sigma^2$, the global error variance) are helpful, it's important to be able to inspect the trees in a BART / BCF model (or a custom tree ensemble model). This vignette walks through some of the features `stochtree` provides to query and understand the forests / trees in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from stochtree import BARTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo 1: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate sample data where feature 10 is the only \"important\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNG\n",
    "random_seed = 1234\n",
    "rng = np.random.default_rng(random_seed)\n",
    "\n",
    "# Generate covariates and basis\n",
    "n = 500\n",
    "p_X = 10\n",
    "X = rng.uniform(0, 1, (n, p_X))\n",
    "\n",
    "\n",
    "# Define the outcome mean function\n",
    "def outcome_mean(X):\n",
    "    return np.where(\n",
    "        (X[:, 9] >= 0.0) & (X[:, 9] < 0.25),\n",
    "        -7.5,\n",
    "        np.where(\n",
    "            (X[:, 9] >= 0.25) & (X[:, 9] < 0.5),\n",
    "            -2.5,\n",
    "            np.where((X[:, 9] >= 0.5) & (X[:, 9] < 0.75), 2.5, 7.5),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "# Generate outcome\n",
    "epsilon = rng.normal(0, 1, n)\n",
    "y = outcome_mean(X) + epsilon\n",
    "\n",
    "# Standardize outcome\n",
    "y_bar = np.mean(y)\n",
    "y_std = np.std(y)\n",
    "resid = (y - y_bar) / y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_inds = np.arange(n)\n",
    "train_inds, test_inds = train_test_split(sample_inds, test_size=0.5)\n",
    "X_train = X[train_inds, :]\n",
    "X_test = X[test_inds, :]\n",
    "y_train = y[train_inds]\n",
    "y_test = y[test_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_model = BARTModel()\n",
    "param_dict = {\"keep_gfr\": True}\n",
    "bart_model.sample(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    num_gfr=10,\n",
    "    num_mcmc=10,\n",
    "    mean_forest_params=param_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the MCMC (BART) samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_preds_y_mcmc = bart_model.y_hat_test\n",
    "y_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis=1, keepdims=True)\n",
    "y_df_mcmc = pd.DataFrame(\n",
    "    np.concatenate((np.expand_dims(y_test, 1), y_avg_mcmc), axis=1),\n",
    "    columns=[\"True outcome\", \"Average estimated outcome\"],\n",
    ")\n",
    "sns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\")\n",
    "plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3, 3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_df_mcmc = pd.DataFrame(\n",
    "    np.concatenate(\n",
    "        (\n",
    "            np.expand_dims(np.arange(bart_model.num_samples), axis=1),\n",
    "            np.expand_dims(bart_model.global_var_samples, axis=1),\n",
    "        ),\n",
    "        axis=1,\n",
    "    ),\n",
    "    columns=[\"Sample\", \"Sigma\"],\n",
    ")\n",
    "sns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the test set RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(np.power(y_test - np.squeeze(y_avg_mcmc), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the variable split count in the last \"GFR\" sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_model.forest_container_mean.get_forest_split_counts(9, p_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_model.forest_container_mean.get_overall_split_counts(p_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split counts appear relatively uniform across features, so let's dig deeper and look at individual trees, starting with the first tree in the last \"grow-from-root\" sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = bart_model.forest_container_mean.get_granular_split_counts(p_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[9, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tree has a single split on the only \"important\" feature. Now, let's look at the second tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[9, 1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tree also only splits on the important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[9, 20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[9, 30, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that \"later\" trees are splitting on other features, but we also note that these trees are fitting an outcome that is already residualized many \"relevant splits\" made by trees 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's inspect the first tree for this last GFR sample in more depth, following [this scikit-learn vignette](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_num = 9\n",
    "tree_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = np.sort(bart_model.forest_container_mean.nodes(forest_num, tree_num))\n",
    "for nid in nodes:\n",
    "    if bart_model.forest_container_mean.is_leaf_node(forest_num, tree_num, nid):\n",
    "        print(\n",
    "            \"{space}node={node} is a leaf node with value={value}.\".format(\n",
    "                space=bart_model.forest_container_mean.node_depth(\n",
    "                    forest_num, tree_num, nid\n",
    "                )\n",
    "                * \"\\t\",\n",
    "                node=nid,\n",
    "                value=np.around(\n",
    "                    bart_model.forest_container_mean.node_leaf_values(\n",
    "                        forest_num, tree_num, nid\n",
    "                    ),\n",
    "                    3,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"{space}node={node} is a split node, which tells us to \"\n",
    "            \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "            \"else to node {right}.\".format(\n",
    "                space=bart_model.forest_container_mean.node_depth(\n",
    "                    forest_num, tree_num, nid\n",
    "                )\n",
    "                * \"\\t\",\n",
    "                node=nid,\n",
    "                left=bart_model.forest_container_mean.left_child_node(\n",
    "                    forest_num, tree_num, nid\n",
    "                ),\n",
    "                feature=bart_model.forest_container_mean.node_split_index(\n",
    "                    forest_num, tree_num, nid\n",
    "                ),\n",
    "                threshold=bart_model.forest_container_mean.node_split_threshold(\n",
    "                    forest_num, tree_num, nid\n",
    "                ),\n",
    "                right=bart_model.forest_container_mean.right_child_node(\n",
    "                    forest_num, tree_num, nid\n",
    "                ),\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
