{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"StochTree","text":"<p><code>stochtree</code> (stochastic tree) is software for building stochastic tree ensembles (i.e. BART, XBART) for supervised learning and causal inference.</p>"},{"location":"getting-started.html","title":"Getting Started","text":"<p><code>stochtree</code> is composed of a C++ \"core\" and R / Python interfaces to that core. Details on installation and use are available below:</p>"},{"location":"getting-started.html#python-package","title":"Python Package","text":"<p>The python package is not yet on PyPI but can be installed from source using pip's git interface.  To proceed, you will need a working version of git and python 3.8 or greater (available from several sources, one of the most  straightforward being the anaconda suite).</p>"},{"location":"getting-started.html#quick-start","title":"Quick start","text":"<p>Without worrying about virtual environments (detailed further below), <code>stochtree</code> can be installed from the command line</p> <pre><code>pip install numpy scipy pytest pandas scikit-learn pybind11\npip install git+https://github.com/StochasticTree/stochtree.git\n</code></pre>"},{"location":"getting-started.html#virtual-environment-installation","title":"Virtual environment installation","text":"<p>Often, users prefer to manage different projects (with different package / python version requirements) in virtual environments. </p>"},{"location":"getting-started.html#conda","title":"Conda","text":"<p>Conda provides a straightforward experience in managing python dependencies, avoiding version conflicts / ABI issues / etc.</p> <p>To build stochtree using a <code>conda</code> based workflow, first create and activate a conda environment with the requisite dependencies</p> <pre><code>conda create -n stochtree-dev -c conda-forge python=3.10 numpy scipy pytest pandas pybind11 scikit-learn matplotlib seaborn\nconda activate stochtree-dev\n</code></pre> <p>Then install the package from github via pip</p> <pre><code>pip install git+https://github.com/StochasticTree/stochtree.git\n</code></pre> <p>(Note: if you'd also like to run <code>stochtree</code>'s notebook examples, you will also need jupyterlab, seaborn, and matplotlib)</p> <pre><code>conda install matplotlib seaborn\npip install jupyterlab\n</code></pre> <p>With these dependencies installed, you can clone the repo and run the <code>demo/</code> examples.</p>"},{"location":"getting-started.html#venv","title":"Venv","text":"<p>You could also use venv for environment management. First, navigate to the folder in which you usually store virtual environments  (i.e. <code>cd /path/to/envs</code>) and create and activate a virtual environment:</p> <pre><code>python -m venv venv\nsource venv/bin/activate\n</code></pre> <p>Install all of the package (and demo notebook) dependencies</p> <pre><code>pip install numpy scipy pytest pandas scikit-learn pybind11\n</code></pre> <p>Then install stochtree via</p> <pre><code>pip install git+https://github.com/StochasticTree/stochtree.git\n</code></pre> <p>As above, if you'd like to run the notebook examples in the <code>demo/</code> subfolder, you will also need jupyterlab, seaborn, and matplotlib and you will have to clone the repo</p> <pre><code>pip install matplotlib seaborn jupyterlab\n</code></pre>"},{"location":"getting-started.html#r-package","title":"R Package","text":"<p>The package can be installed in R via</p> <pre><code>remotes::install_github(\"StochasticTree/stochtree\", ref=\"r-dev\")\n</code></pre>"},{"location":"getting-started.html#c-core","title":"C++ Core","text":"<p>While the C++ core links to both R and Python for a performant, high-level interface,  the C++ code can be compiled and unit-tested and compiled into a standalone  debug program.</p>"},{"location":"getting-started.html#compilation","title":"Compilation","text":""},{"location":"getting-started.html#cloning-the-repository","title":"Cloning the Repository","text":"<p>To clone the repository, you must have git installed, which you can do following these instructions. </p> <p>Once git is available at the command line, navigate to the folder that will store this project (in bash / zsh, this is done by running <code>cd</code> followed by the path to the directory).  Then, clone the <code>stochtree</code> repo as a subfolder by running</p> <pre><code>git clone --recursive https://github.com/StochasticTree/stochtree.git\n</code></pre> <p>NOTE: this project incorporates several dependencies as git submodules,  which is why the <code>--recursive</code> flag is necessary (some systems may perform a recursive clone without this flag, but  <code>--recursive</code> ensures this behavior on all platforms). If you have already cloned the repo without the <code>--recursive</code> flag,  you can retrieve the submodules recursively by running <code>git submodule update --init --recursive</code> in the main repo directory.</p>"},{"location":"getting-started.html#cmake-build","title":"CMake Build","text":"<p>The C++ project can be built independently from the R / Python packages using <code>cmake</code>.  See here for details on installing cmake (alternatively,  on MacOS, <code>cmake</code> can be installed using homebrew). Once <code>cmake</code> is installed, you can build the CLI by navigating to the main  project directory at your command line (i.e. <code>cd /path/to/stochtree</code>) and  running the following code </p> <pre><code>rm -rf build\nmkdir build\ncmake -S . -B build\ncmake --build build\n</code></pre> <p>The CMake build has two primary targets, which are detailed below</p>"},{"location":"getting-started.html#debug-program","title":"Debug Program","text":"<p><code>debug/api_debug.cpp</code> defines a standalone target that can be straightforwardly run with a debugger (i.e. <code>lldb</code>, <code>gdb</code>)  while making non-trivial changes to the C++ code. This debugging program is compiled as part of the CMake build if the <code>BUILD_DEBUG_TARGETS</code> option in <code>CMakeLists.txt</code> is set to <code>ON</code>.</p> <p>Once the program has been built, it can be run from the command line via <code>./build/debugstochtree</code> or attached to a debugger  via <code>lldb ./build/debugstochtree</code> (clang) or <code>gdb ./build/debugstochtree</code> (gcc).</p>"},{"location":"getting-started.html#unit-tests","title":"Unit Tests","text":"<p>We test <code>stochtree</code> using the GoogleTest framework. Unit tests are compiled into a single target as part of the CMake build if the <code>BUILD_TEST</code> option is set to <code>ON</code>  and the test suite can be run after compilation via <code>./build/teststochtree</code></p>"},{"location":"getting-started.html#xcode","title":"Xcode","text":"<p>While using <code>gdb</code> or <code>lldb</code> on <code>debugstochtree</code> at the command line is very helpful, users may prefer debugging in a full-fledged IDE like xcode. This project's C++ core can be converted to an xcode project from <code>CMakeLists.txt</code>, but first you must turn off sanitizers (xcode seems to have its own way of setting this at build time for different configurations, and having injected  <code>-fsanitize=address</code> statically into compiler arguments will cause xcode errors). To do this, modify the <code>USE_SANITIZER</code> line in <code>CMakeLists.txt</code>:</p> <pre><code>option(USE_SANITIZER \"Use santizer flags\" OFF)\n</code></pre> <p>To generate an XCode project based on the build targets and specifications defined in a <code>CMakeLists.txt</code>, navigate to the main project folder (i.e. <code>cd /path/to/project</code>) and run the following commands:</p> <pre><code>rm -rf xcode/\nmkdir xcode\ncd xcode\ncmake -G Xcode .. -DCMAKE_C_COMPILER=cc -DCMAKE_CXX_COMPILER=c++ -DUSE_SANITIZER=OFF -DUSE_DEBUG=OFF\ncd ..\n</code></pre> <p>Now, if you navigate to the xcode subfolder (in Finder), you should be able to click on a <code>.xcodeproj</code> file and the project will open in XCode.</p>"},{"location":"R_docs/index.html","title":"StochTree R API Reference","text":"<p>Overview of the <code>stochtree</code> R library's key classes and functions, built as a self-contained doc site using the pkgdown format. The <code>stochtree</code> interface is divided into two \"levels\":</p> <ol> <li>\"High level\": end-to-end implementations of stochastic tree ensembles for supervised learning (BART / XBART) and causal inference (BCF / XBCF). <ol> <li>The BART (supervised learning) interface is documented here.</li> <li>The BCF (causal inference) interface is documented here.</li> </ol> </li> <li>\"Low level\": we provide access to most of the C++ sampling objects and functionality via R, which allow for custom sampling algorithms and integration of other model terms. This interface consists broadly of the following components:<ol> <li>Data API: loading and storing in-memory data needed to train <code>stochtree</code> models.</li> <li>Forest API: creating, storing, modifying, and sampling ensembles of decision trees that underlie all <code>stochtree</code> models.</li> <li>Serialization API: serializing models to JSON (files or in-memory strings).</li> <li>Random Effects API: sampling from additive random effects models.</li> </ol> </li> </ol>"},{"location":"cpp_docs/index.html","title":"StochTree C++ API","text":"<p>This page documents the data structures and interfaces that constitute the <code>stochtree</code> C++ core.  It may be useful to researchers building novel tree algorithms or users seeking a deeper understanding of the algorithms implemented in <code>stochtree</code>. This resource is split into:</p> <ol> <li>Technical documentation of the design / computational aspects of the C++ core<ol> <li>Tree API: decision tree class which underpins the ensembles that <code>stochtree</code> samples</li> <li>Tracker API: temporary data structures that synchronize a training dataset and the current state of a decision tree ensemble for faster sampling </li> </ol> </li> <li>Doxygen site with auto-generated documentation of C++ classes and functions</li> </ol>"},{"location":"cpp_docs/tracking.html","title":"Forest Sampling Tracker API","text":"<p>A truly minimalist tree ensemble library only needs </p> <ul> <li>A representation of a decision tree</li> <li>A container for grouping / storing ensembles of trees</li> <li>In-memory access to / representation of training data</li> <li>Routines / functions to construct the trees</li> </ul> <p>Most algorithms for optimizing or sampling tree ensembles frequently perform the following operations</p> <ul> <li>Determine which leaf a training observation falls into for a decision tree (to compute its prediction and update the residual / outcome)</li> <li>Evaluate potential split candidates for a leaf of a decision</li> </ul> <p>With only the \"minimalist\" tools above, these two tasks proceed largely as follows</p> <ul> <li>For every observation in the dataset, traverse the tree (runtime depends on the tree topology but in a fully balanced tree with \\(k\\) leaf nodes, this has time complexity \\(O(N \\log (k))\\)).</li> <li>For a given node, determine which observations in the training set fall into this node. This requires \\(O(N)\\) boolean operations.</li> </ul> <p>These operations both perform unnecessary computation which can be avoided with some additional real-time tracking. Essentially, we want </p> <ol> <li>A mapping from dataset row index to leaf node id for every tree in an ensemble (so that we can skip the tree traversal during prediction)</li> <li>A mapping from leaf node id to dataset row indices every tree in an ensemble (so that we can skip the full pass through the training data at split evaluation)</li> </ol>"},{"location":"cpp_docs/tracking.html#forest-tracker","title":"Forest Tracker","text":"<p>The <code>ForestTracker</code> class is a wrapper around several implementations of the mappings discussed above. </p>"},{"location":"cpp_docs/tree.html","title":"Decision Tree API","text":""},{"location":"cpp_docs/tree.html#tree","title":"Tree","text":"<p>The fundamental building block of the C++ tree interface is the <code>Tree</code> class. </p>"},{"location":"cpp_docs/tree.html#tree-split","title":"Tree Split","text":"<p>Numeric and categorical splits are represented by a <code>TreeSplit</code> class.</p>"},{"location":"python_docs/index.html","title":"StochTree Python Library","text":"<p>The stochtree python library provides two essential components:</p> <ol> <li>High-level functionality for sampling, predicting, and serializing BART and BCF models</li> <li>Lower-level definition and control of a stochastic tree sampler</li> </ol>"},{"location":"python_docs/api/index.html","title":"StochTree Python API Reference","text":"<p>Overview of the <code>stochtree</code> python library's key classes and functions.</p> <p>The <code>stochtree</code> interface is divided into two \"levels\":</p> <ol> <li>\"High level\": end-to-end implementations of stochastic tree ensembles for supervised learning (BART / XBART) and causal inference (BCF / XBCF). Both interfaces are designed to mirror the scikit-learn estimator style, with the <code>.fit()</code> method replaced by a <code>.sample()</code> method.<ol> <li>The BART (supervised learning) interface is documented here.</li> <li>The BCF (causal inference) interface is documented here.</li> </ol> </li> <li>\"Low level\": we provide access to most of the C++ sampling objects and functionality via Python, which allow for custom sampling algorithms and integration of other model terms. This interface is documented here and consists broadly of the following components:<ol> <li>Data API: loading and storing in-memory data needed to train <code>stochtree</code> models.</li> <li>Forest API: creating, storing, and modifying ensembles of decision trees that underlie all <code>stochtree</code> models.</li> <li>Sampler API: sampling from stochastic tree ensemble models as well as several supported parametric models.</li> <li>Utilities API: seeding a C++ random number generator, preprocessing data, and serializing models to JSON (files or in-memory strings).</li> </ol> </li> </ol>"},{"location":"python_docs/api/bart.html","title":"BART","text":""},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel","title":"<code>stochtree.bart.BARTModel</code>","text":"<p>Class that handles sampling, storage, and serialization of stochastic forest models for supervised learning.  The class takes its name from Bayesian Additive Regression Trees, an MCMC sampler originally developed in  Chipman, George, McCulloch (2010), but supports several sampling algorithms:</p> <ul> <li>MCMC: The \"classic\" sampler defined in Chipman, George, McCulloch (2010). In order to run the MCMC sampler, set <code>num_gfr = 0</code> (explained below) and then define a sampler according to several parameters:<ul> <li><code>num_burnin</code>: the number of iterations to run before \"retaining\" samples for further analysis. These \"burned in\" samples are helpful for allowing a sampler to converge before retaining samples.</li> <li><code>num_chains</code>: the number of independent sequences of MCMC samples to generate (typically referred to in the literature as \"chains\")</li> <li><code>num_mcmc</code>: the number of \"retained\" samples of the posterior distribution</li> <li><code>keep_every</code>: after a sampler has \"burned in\", we will run the sampler for <code>keep_every</code> * <code>num_mcmc</code> iterations, retaining one of each <code>keep_every</code> iteration in a chain.</li> </ul> </li> <li>GFR (Grow-From-Root): A fast, greedy approximation of the BART MCMC sampling algorithm introduced in He and Hahn (2021). GFR sampler iterations are governed by the <code>num_gfr</code> parameter, and there are two primary ways to use this sampler:<ul> <li>Standalone: setting <code>num_gfr &gt; 0</code> and both <code>num_burnin = 0</code> and <code>num_mcmc = 0</code> will only run and retain GFR samples of the posterior. This is typically referred to as \"XBART\" (accelerated BART).</li> <li>Initializer for MCMC: setting <code>num_gfr &gt; 0</code> and <code>num_mcmc &gt; 0</code> will use ensembles from the GFR algorithm to initialize <code>num_chains</code> independent MCMC BART samplers, which are run for <code>num_mcmc</code> iterations. This is typically referred to as \"warm start BART\".</li> </ul> </li> </ul> <p>In addition to enabling multiple samplers, we support a broad set of models. First, note that the original BART model of Chipman, George, McCulloch (2010) is</p> \\[\\begin{equation*} \\begin{aligned} y &amp;= f(X) + \\epsilon\\\\ f(X) &amp;\\sim \\text{BART}(\\cdot)\\\\ \\epsilon &amp;\\sim N(0, \\sigma^2)\\\\ \\sigma^2 &amp;\\sim IG(\\nu, \\nu\\lambda) \\end{aligned} \\end{equation*}\\] <p>In words, there is a nonparametric mean function governed by a tree ensemble with a BART prior and an additive (mean-zero) Gaussian error  term, whose variance is parameterized with an inverse gamma prior.</p> <p>The <code>BARTModel</code> class supports the following extensions of this model:</p> <ul> <li>Leaf Regression: Rather than letting <code>f(X)</code> define a standard decision tree ensemble, in which each tree uses <code>X</code> to partition the data and then serve up constant predictions, we allow for models <code>f(X,Z)</code> in which <code>X</code> and <code>Z</code> together define a partitioned linear model (<code>X</code> partitions the data and <code>Z</code> serves as the basis for regression models). This model can be run by specifying <code>basis_train</code> in the <code>sample</code> method.</li> <li>Heteroskedasticity: Rather than define \\(\\epsilon\\) parameterically, we can let a forest \\(\\sigma^2(X)\\) model a conditional error variance function. This can be done by setting <code>num_trees_variance &gt; 0</code> in the <code>params</code> dictionary passed to the <code>sample</code> method.</li> </ul>"},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel.sample","title":"<code>sample(X_train, y_train, basis_train=None, X_test=None, basis_test=None, num_gfr=5, num_burnin=0, num_mcmc=100, params=None)</code>","text":"<p>Runs a BART sampler on provided training set. Predictions will be cached for the training set and (if provided) the test set.  Does not require a leaf regression basis. </p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>array</code> <p>Training set covariates on which trees may be partitioned.</p> required <code>y_train</code> <code>array</code> <p>Training set outcome.</p> required <code>basis_train</code> <code>array</code> <p>Optional training set basis vector used to define a regression to be run in the leaves of each tree.</p> <code>None</code> <code>X_test</code> <code>array</code> <p>Optional test set covariates.</p> <code>None</code> <code>basis_test</code> <code>array</code> <p>Optional test set basis vector used to define a regression to be run in the leaves of each tree.  Must be included / omitted consistently (i.e. if basis_train is provided, then basis_test must be provided alongside X_test).</p> <code>None</code> <code>num_gfr</code> <code>int</code> <p>Number of \"warm-start\" iterations run using the grow-from-root algorithm (He and Hahn, 2021). Defaults to <code>5</code>.</p> <code>5</code> <code>num_burnin</code> <code>int</code> <p>Number of \"burn-in\" iterations of the MCMC sampler. Defaults to <code>0</code>. Ignored if <code>num_gfr &gt; 0</code>.</p> <code>0</code> <code>num_mcmc</code> <code>int</code> <p>Number of \"retained\" iterations of the MCMC sampler. Defaults to <code>100</code>. If this is set to 0, GFR (XBART) samples will be retained.</p> <code>100</code> <code>params</code> <code>dict</code> <p>Dictionary of model parameters, each of which has a default value.</p> <ul> <li><code>cutpoint_grid_size</code> (<code>int</code>): Maximum number of cutpoints to consider for each feature. Defaults to <code>100</code>.</li> <li><code>sigma_leaf</code> (<code>float</code>): Scale parameter on the (conditional mean) leaf node regression model.</li> <li><code>alpha_mean</code> (<code>float</code>): Prior probability of splitting for a tree of depth 0 in the conditional mean model. Tree split prior combines <code>alpha_mean</code> and <code>beta_mean</code> via <code>alpha_mean*(1+node_depth)^-beta_mean</code>.</li> <li><code>beta_mean</code> (<code>float</code>): Exponent that decreases split probabilities for nodes of depth &gt; 0 in the conditional mean model. Tree split prior combines <code>alpha_mean</code> and <code>beta_mean</code> via <code>alpha_mean*(1+node_depth)^-beta_mean</code>.</li> <li><code>min_samples_leaf_mean</code> (<code>int</code>): Minimum allowable size of a leaf, in terms of training samples, in the conditional mean model. Defaults to <code>5</code>.</li> <li><code>max_depth_mean</code> (<code>int</code>): Maximum depth of any tree in the ensemble in the conditional mean model. Defaults to <code>10</code>. Can be overriden with <code>-1</code> which does not enforce any depth limits on trees.</li> <li><code>alpha_variance</code> (<code>float</code>): Prior probability of splitting for a tree of depth 0 in the conditional variance model. Tree split prior combines <code>alpha_variance</code> and <code>beta_variance</code> via <code>alpha_variance*(1+node_depth)^-beta_variance</code>.</li> <li><code>beta_variance</code> (<code>float</code>): Exponent that decreases split probabilities for nodes of depth &gt; 0 in the conditional variance model. Tree split prior combines <code>alpha_variance</code> and <code>beta_variance</code> via <code>alpha_variance*(1+node_depth)^-beta_variance</code>.</li> <li><code>min_samples_leaf_variance</code> (<code>int</code>): Minimum allowable size of a leaf, in terms of training samples in the conditional variance model. Defaults to <code>5</code>.</li> <li><code>max_depth_variance</code> (<code>int</code>): Maximum depth of any tree in the ensemble in the conditional variance model. Defaults to <code>10</code>. Can be overriden with <code>-1</code> which does not enforce any depth limits on trees.</li> <li><code>a_global</code> (<code>float</code>): Shape parameter in the <code>IG(a_global, b_global)</code> global error variance model. Defaults to <code>0</code>.</li> <li><code>b_global</code> (<code>float</code>): Scale parameter in the <code>IG(a_global, b_global)</code> global error variance prior. Defaults to <code>0</code>.</li> <li><code>a_leaf</code> (<code>float</code>): Shape parameter in the <code>IG(a_leaf, b_leaf)</code> leaf node parameter variance model. Defaults to <code>3</code>.</li> <li><code>b_leaf</code> (<code>float</code>): Scale parameter in the <code>IG(a_leaf, b_leaf)</code> leaf node parameter variance model. Calibrated internally as <code>0.5/num_trees_mean</code> if not set here.</li> <li><code>a_forest</code> (<code>float</code>): Shape parameter in the [optional] <code>IG(a_forest, b_forest)</code> conditional error variance forest (which is only sampled if <code>num_trees_variance &gt; 0</code>). Calibrated internally as <code>num_trees_variance / 1.5^2 + 0.5</code> if not set here.</li> <li><code>b_forest</code> (<code>float</code>): Scale parameter in the [optional] <code>IG(a_forest, b_forest)</code> conditional error variance forest (which is only sampled if <code>num_trees_variance &gt; 0</code>). Calibrated internally as <code>num_trees_variance / 1.5^2</code> if not set here.</li> <li><code>sigma2_init</code> (<code>float</code>): Starting value of global variance parameter. Set internally as a percentage of the standardized outcome variance if not set here.</li> <li><code>variance_forest_leaf_init</code> (<code>float</code>): Starting value of root forest prediction in conditional (heteroskedastic) error variance model. Calibrated internally as <code>np.log(pct_var_variance_forest_init*np.var((y-np.mean(y))/np.std(y)))/num_trees_variance</code> if not set.</li> <li><code>pct_var_sigma2_init</code> (<code>float</code>): Percentage of standardized outcome variance used to initialize global error variance parameter. Superseded by <code>sigma2</code>. Defaults to <code>1</code>.</li> <li><code>pct_var_variance_forest_init</code> (<code>float</code>): Percentage of standardized outcome variance used to initialize global error variance parameter. Default: <code>1</code>. Superseded by <code>variance_forest_init</code>.</li> <li><code>variance_scale</code> (<code>float</code>): Variance after the data have been scaled. Default: <code>1</code>.</li> <li><code>variable_weights_mean</code> (<code>np.array</code>): Numeric weights reflecting the relative probability of splitting on each variable in the mean forest. Does not need to sum to 1 but cannot be negative. Defaults to uniform over the columns of <code>X_train</code> if not provided.</li> <li><code>variable_weights_variance</code> (<code>np.array</code>): Numeric weights reflecting the relative probability of splitting on each variable in the variance forest. Does not need to sum to 1 but cannot be negative. Defaults to uniform over the columns of <code>X_train</code> if not provided.</li> <li><code>num_trees_mean</code> (<code>int</code>): Number of trees in the ensemble for the conditional mean model. Defaults to <code>200</code>. If <code>num_trees_mean = 0</code>, the conditional mean will not be modeled using a forest and the function will only proceed if <code>num_trees_variance &gt; 0</code>.</li> <li><code>num_trees_variance</code> (<code>int</code>): Number of trees in the ensemble for the conditional variance model. Defaults to <code>0</code>. Variance is only modeled using a tree / forest if <code>num_trees_variance &gt; 0</code>.</li> <li><code>sample_sigma_global</code> (<code>bool</code>): Whether or not to update the <code>sigma^2</code> global error variance parameter based on <code>IG(a_global, b_global)</code>. Defaults to <code>True</code>.</li> <li><code>sample_sigma_leaf</code> (<code>bool</code>): Whether or not to update the <code>tau</code> leaf scale variance parameter based on <code>IG(a_leaf, b_leaf)</code>. Cannot (currently) be set to true if <code>basis_train</code> has more than one column. Defaults to <code>False</code>.</li> <li><code>random_seed</code> (<code>int</code>): Integer parameterizing the C++ random number generator. If not specified, the C++ random number generator is seeded according to <code>std::random_device</code>.</li> <li><code>keep_burnin</code> (<code>bool</code>): Whether or not \"burnin\" samples should be included in predictions. Defaults to <code>False</code>. Ignored if <code>num_mcmc == 0</code>.</li> <li><code>keep_gfr</code> (<code>bool</code>): Whether or not \"warm-start\" / grow-from-root samples should be included in predictions. Defaults to <code>False</code>. Ignored if <code>num_mcmc == 0</code>.</li> <li><code>num_chains</code> (<code>int</code>): How many independent MCMC chains should be sampled. If <code>num_mcmc = 0</code>, this is ignored. If <code>num_gfr = 0</code>, then each chain is run from root for <code>num_mcmc * keep_every + num_burnin</code> iterations, with <code>num_mcmc</code> samples retained. If <code>num_gfr &gt; 0</code>, each MCMC chain will be initialized from a separate GFR ensemble, with the requirement that <code>num_gfr &gt;= num_chains</code>. Default: <code>1</code>.</li> <li><code>keep_every</code> (<code>int</code>): How many iterations of the burned-in MCMC sampler should be run before forests and parameters are retained. Defaults to <code>1</code>. Setting <code>keep_every = k</code> for some <code>k &gt; 1</code> will \"thin\" the MCMC samples by retaining every <code>k</code>-th sample, rather than simply every sample. This can reduce the autocorrelation of the MCMC samples.</li> </ul> <code>None</code>"},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel.predict","title":"<code>predict(covariates, basis=None)</code>","text":"<p>Return predictions from every forest sampled (either / both of mean and variance).  Return type is either a single array of predictions, if a BART model only includes a  mean or variance term, or a tuple of prediction arrays, if a BART model includes both.</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array</code> <p>Test set covariates.</p> required <code>basis</code> <code>array</code> <p>Optional test set basis vector, must be provided if the model was trained with a leaf regression basis.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mu_x</code> <code>(array, optional)</code> <p>Mean forest predictions.</p> <code>sigma2_x</code> <code>(array, optional)</code> <p>Variance forest predictions.</p>"},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel.predict_mean","title":"<code>predict_mean(covariates, basis=None)</code>","text":"<p>Predict expected conditional outcome from a BART model.</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array</code> <p>Test set covariates.</p> required <code>basis</code> <code>array</code> <p>Optional test set basis vector, must be provided if the model was trained with a leaf regression basis.</p> <code>None</code> <p>Returns:</p> Type Description <code>array</code> <p>Mean forest predictions.</p>"},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel.predict_variance","title":"<code>predict_variance(covariates)</code>","text":"<p>Predict expected conditional variance from a BART model.</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array</code> <p>Test set covariates.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Variance forest predictions.</p>"},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel.to_json","title":"<code>to_json()</code>","text":"<p>Converts a sampled BART model to JSON string representation (which can then be saved to a file or  processed using the <code>json</code> library)</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON string representing model metadata (hyperparameters), sampled parameters, and sampled forests</p>"},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel.from_json","title":"<code>from_json(json_string)</code>","text":"<p>Converts a JSON string to an in-memory BART model.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representing model metadata (hyperparameters), sampled parameters, and sampled forests</p> required"},{"location":"python_docs/api/bart.html#stochtree.bart.BARTModel.is_sampled","title":"<code>is_sampled()</code>","text":"<p>Whether or not a BART model has been sampled.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if a BART model has been sampled, <code>False</code> otherwise</p>"},{"location":"python_docs/api/bcf.html","title":"BCF","text":""},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel","title":"<code>stochtree.bcf.BCFModel</code>","text":"<p>Class that handles sampling, storage, and serialization of stochastic forest models for causal effect estimation.  The class takes its name from Bayesian Causal Forests, an MCMC sampler originally developed in  Hahn, Murray, Carvalho (2020), but supports several sampling algorithms:</p> <ul> <li>MCMC: The \"classic\" sampler defined in Hahn, Murray, Carvalho (2020). In order to run the MCMC sampler,  set <code>num_gfr = 0</code> (explained below) and then define a sampler according to several parameters:<ul> <li><code>num_burnin</code>: the number of iterations to run before \"retaining\" samples for further analysis. These \"burned in\" samples  are helpful for allowing a sampler to converge before retaining samples.</li> <li><code>num_chains</code>: the number of independent sequences of MCMC samples to generate (typically referred to in the literature as \"chains\")</li> <li><code>num_mcmc</code>: the number of \"retained\" samples of the posterior distribution</li> <li><code>keep_every</code>: after a sampler has \"burned in\", we will run the sampler for <code>keep_every</code> * <code>num_mcmc</code> iterations, retaining one of each <code>keep_every</code> iteration in a chain.</li> </ul> </li> <li>GFR (Grow-From-Root): A fast, greedy approximation of the BART MCMC sampling algorithm introduced in Krantsevich, He, and Hahn (2023). GFR sampler iterations are  governed by the <code>num_gfr</code> parameter, and there are two primary ways to use this sampler:<ul> <li>Standalone: setting <code>num_gfr &gt; 0</code> and both <code>num_burnin = 0</code> and <code>num_mcmc = 0</code> will only run and retain GFR samples of the posterior. This is typically referred to as \"XBART\" (accelerated BART).</li> <li>Initializer for MCMC: setting <code>num_gfr &gt; 0</code> and <code>num_mcmc &gt; 0</code> will use ensembles from the GFR algorithm to initialize <code>num_chains</code> independent MCMC BART samplers, which are run for <code>num_mcmc</code> iterations.  This is typically referred to as \"warm start BART\".</li> </ul> </li> </ul> <p>In addition to enabling multiple samplers, we support a broad set of models. First, note that the original BCF model of Hahn, Murray, Carvalho (2020) is</p> \\[\\begin{equation*} \\begin{aligned} y &amp;= a(X) + b_z(X) + \\epsilon\\\\ b_z(X) &amp;= (b_1 Z + b_0 (1-Z)) t(X)\\\\ b_0, b_1 &amp;\\sim N(0, \\frac{1}{2})\\\\\\\\ a(X) &amp;\\sim \\text{BART}()\\\\ t(X) &amp;\\sim \\text{BART}()\\\\ \\epsilon &amp;\\sim N(0, \\sigma^2)\\\\ \\sigma^2 &amp;\\sim IG(a, b) \\end{aligned} \\end{equation*}\\] <p>for continuous outcome \\(y\\), binary treatment \\(Z\\), and covariates \\(X\\).</p> <p>In words, there are two nonparametric mean functions -- a \"prognostic\" function and a \"treatment effect\" function -- governed by tree ensembles with BART priors and an additive (mean-zero) Gaussian error  term, whose variance is parameterized with an inverse gamma prior.</p> <p>The <code>BCFModel</code> class supports the following extensions of this model:</p> <ul> <li>Continuous Treatment: If \\(Z\\) is continuous rather than binary, we define \\(b_z(X) = \\tau(X, Z) = Z \\tau(X)\\), where the \"leaf model\" for the \\(\\tau\\) forest is essentially a regression on continuous \\(Z\\).</li> <li>Heteroskedasticity: Rather than define \\(\\epsilon\\) parameterically, we can let a forest \\(\\sigma^2(X)\\) model a conditional error variance function. This can be done by setting <code>num_trees_variance &gt; 0</code> in the <code>params</code> dictionary passed to the <code>sample</code> method.</li> </ul>"},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel.sample","title":"<code>sample(X_train, Z_train, y_train, pi_train=None, X_test=None, Z_test=None, pi_test=None, num_gfr=5, num_burnin=0, num_mcmc=100, params=None)</code>","text":"<p>Runs a BCF sampler on provided training set. Outcome predictions and estimates of the prognostic and treatment effect functions  will be cached for the training set and (if provided) the test set.</p> <p>Parameters:</p> Name Type Description Default <code>X_train</code> <code>array or DataFrame</code> <p>Covariates used to split trees in the ensemble. Can be passed as either a matrix or dataframe.</p> required <code>Z_train</code> <code>array</code> <p>Array of (continuous or binary; univariate or multivariate) treatment assignments.</p> required <code>y_train</code> <code>array</code> <p>Outcome to be modeled by the ensemble.</p> required <code>pi_train</code> <code>array</code> <p>Optional vector of propensity scores. If not provided, this will be estimated from the data.</p> <code>None</code> <code>X_test</code> <code>array</code> <p>Optional test set of covariates used to define \"out of sample\" evaluation data.</p> <code>None</code> <code>Z_test</code> <code>array</code> <p>Optional test set of (continuous or binary) treatment assignments. Must be provided if <code>X_test</code> is provided.</p> <code>None</code> <code>pi_test</code> <code>array</code> <p>Optional test set vector of propensity scores. If not provided (but <code>X_test</code> and <code>Z_test</code> are), this will be estimated from the data.</p> <code>None</code> <code>num_gfr</code> <code>int</code> <p>Number of \"warm-start\" iterations run using the grow-from-root algorithm (He and Hahn, 2021). Defaults to <code>5</code>.</p> <code>5</code> <code>num_burnin</code> <code>int</code> <p>Number of \"burn-in\" iterations of the MCMC sampler. Defaults to <code>0</code>. Ignored if <code>num_gfr &gt; 0</code>.</p> <code>0</code> <code>num_mcmc</code> <code>int</code> <p>Number of \"retained\" iterations of the MCMC sampler. Defaults to <code>100</code>. If this is set to 0, GFR (XBART) samples will be retained.</p> <code>100</code> <code>params</code> <code>dict</code> <p>Dictionary of model parameters, each of which has a default value.</p> <ul> <li><code>cutpoint_grid_size</code> (<code>int</code>): Maximum number of cutpoints to consider for each feature. Defaults to <code>100</code>.</li> <li><code>sigma_leaf_mu</code> (<code>float</code>): Starting value of leaf node scale parameter for the prognostic forest. Calibrated internally as <code>2/num_trees_mu</code> if not set here.</li> <li><code>sigma_leaf_tau</code> (<code>float</code> or <code>np.array</code>): Starting value of leaf node scale parameter for the treatment effect forest.      When treatment (<code>Z_train</code>) is multivariate, this can be either a <code>float</code> or a square 2-dimensional <code>np.array</code>      with <code>sigma_leaf_tau.shape[0] == Z_train.shape[1]</code> and <code>sigma_leaf_tau.shape[1] == Z_train.shape[1]</code>.     If <code>sigma_leaf_tau</code> is provided as a float for multivariate treatment, the leaf scale term will be set as a      diagonal matrix with <code>sigma_leaf_tau</code> on every diagonal. If not passed as an argument, this parameter is      calibrated internally as <code>1/num_trees_tau</code> (and propagated to a diagonal matrix if necessary).</li> <li><code>alpha_mu</code> (<code>float</code>): Prior probability of splitting for a tree of depth 0 for the prognostic forest.      Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>.</li> <li><code>alpha_tau</code> (<code>float</code>): Prior probability of splitting for a tree of depth 0 for the treatment effect forest.      Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>.</li> <li><code>alpha_variance</code> (<code>float</code>): Prior probability of splitting for a tree of depth 0 in the conditional variance model. Tree split prior combines <code>alpha_variance</code> and <code>beta_variance</code> via <code>alpha_variance*(1+node_depth)^-beta_variance</code>.</li> <li><code>beta_mu</code> (<code>float</code>): Exponent that decreases split probabilities for nodes of depth &gt; 0 for the prognostic forest.      Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>.</li> <li><code>beta_tau</code> (<code>float</code>): Exponent that decreases split probabilities for nodes of depth &gt; 0 for the treatment effect forest.      Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>.</li> <li><code>beta_variance</code> (<code>float</code>): Exponent that decreases split probabilities for nodes of depth &gt; 0 in the conditional variance model. Tree split prior combines <code>alpha_variance</code> and <code>beta_variance</code> via <code>alpha_variance*(1+node_depth)^-beta_variance</code>.</li> <li><code>min_samples_leaf_mu</code> (<code>int</code>): Minimum allowable size of a leaf, in terms of training samples, for the prognostic forest. Defaults to <code>5</code>.</li> <li><code>min_samples_leaf_tau</code> (<code>int</code>): Minimum allowable size of a leaf, in terms of training samples, for the treatment effect forest. Defaults to <code>5</code>.</li> <li><code>min_samples_leaf_variance</code> (<code>int</code>): Minimum allowable size of a leaf, in terms of training samples in the conditional variance model. Defaults to <code>5</code>.</li> <li><code>max_depth_mu</code> (<code>int</code>): Maximum depth of any tree in the mu ensemble. Defaults to <code>10</code>. Can be overriden with <code>-1</code> which does not enforce any depth limits on trees.</li> <li><code>max_depth_tau</code> (<code>int</code>): Maximum depth of any tree in the tau ensemble. Defaults to <code>5</code>. Can be overriden with <code>-1</code> which does not enforce any depth limits on trees.</li> <li><code>max_depth_variance</code> (<code>int</code>): Maximum depth of any tree in the ensemble in the conditional variance model. Defaults to <code>10</code>. Can be overriden with <code>-1</code> which does not enforce any depth limits on trees.</li> <li><code>a_global</code> (<code>float</code>): Shape parameter in the <code>IG(a_global, b_global)</code> global error variance model. Defaults to <code>0</code>.</li> <li><code>b_global</code> (<code>float</code>): Component of the scale parameter in the <code>IG(a_global, b_global)</code> global error variance prior. Defaults to <code>0</code>.</li> <li><code>a_leaf_mu</code> (<code>float</code>): Shape parameter in the <code>IG(a_leaf, b_leaf)</code> leaf node parameter variance model for the prognostic forest. Defaults to <code>3</code>.</li> <li><code>a_leaf_tau</code> (<code>float</code>): Shape parameter in the <code>IG(a_leaf, b_leaf)</code> leaf node parameter variance model for the treatment effect forest. Defaults to <code>3</code>.</li> <li><code>b_leaf_mu</code> (<code>float</code>): Scale parameter in the <code>IG(a_leaf, b_leaf)</code> leaf node parameter variance model for the prognostic forest. Calibrated internally as <code>0.5/num_trees</code> if not set here.</li> <li><code>b_leaf_tau</code> (<code>float</code>): Scale parameter in the <code>IG(a_leaf, b_leaf)</code> leaf node parameter variance model for the treatment effect forest. Calibrated internally as <code>0.5/num_trees</code> if not set here.</li> <li><code>sigma2_init</code> (<code>float</code>): Starting value of global variance parameter. Calibrated internally as in Sparapani et al (2021) if not set here.</li> <li><code>variance_forest_leaf_init</code> (<code>float</code>): Starting value of root forest prediction in conditional (heteroskedastic) error variance model. Calibrated internally as <code>np.log(pct_var_variance_forest_init*np.var((y-np.mean(y))/np.std(y)))/num_trees_variance</code> if not set.</li> <li><code>pct_var_sigma2_init</code> (<code>float</code>): Percentage of standardized outcome variance used to initialize global error variance parameter. Superseded by <code>sigma2</code>. Defaults to <code>0.25</code>.</li> <li><code>pct_var_variance_forest_init</code> (<code>float</code>): Percentage of standardized outcome variance used to initialize global error variance parameter. Default: <code>1</code>. Superseded by <code>variance_forest_init</code>.</li> <li><code>variable_weights_mean</code> (<code>np.</code>array<code>): Numeric weights reflecting the relative probability of splitting on each variable in the prognostic and treatment effect forests. Does not need to sum to 1 but cannot be negative. Defaults to</code>np.repeat(1/X_train.shape[1], X_train.shape[1])<code>if not set here. Note that if the propensity score is included as a covariate in either forest, its weight will default to</code>1/X_train.shape[1]<code>. A workaround if you wish to provide a custom weight for the propensity score is to include it as a column in</code>X_train<code>and then set</code>propensity_covariate<code>to</code>'none'<code>and adjust</code>keep_vars_mu<code>and</code>keep_vars_tau` accordingly.</li> <li><code>variable_weights_variance</code> (<code>np.array</code>): Numeric weights reflecting the relative probability of splitting on each variable in the variance forest. Does not need to sum to 1 but cannot be negative. Defaults to uniform over the columns of <code>X_train</code> if not provided.</li> <li><code>keep_vars_mu</code> (<code>list</code> or <code>np.array</code>): Vector of variable names or column indices denoting variables that should be included in the prognostic (<code>mu(X)</code>) forest. Defaults to <code>None</code>.</li> <li><code>drop_vars_mu</code> (<code>list</code> or <code>np.array</code>): Vector of variable names or column indices denoting variables that should be excluded from the prognostic (<code>mu(X)</code>) forest. Defaults to <code>None</code>. If both <code>drop_vars_mu</code> and <code>keep_vars_mu</code> are set, <code>drop_vars_mu</code> will be ignored.</li> <li><code>drop_vars_variance</code> (<code>list</code> or <code>np.array</code>): Vector of variable names or column indices denoting variables that should be excluded from the variance (<code>sigma^2(X)</code>) forest. Defaults to <code>None</code>. If both <code>drop_vars_variance</code> and <code>keep_vars_variance</code> are set, <code>drop_vars_variance</code> will be ignored.</li> <li><code>keep_vars_tau</code> (<code>list</code> or <code>np.array</code>): Vector of variable names or column indices denoting variables that should be included in the treatment effect (<code>tau(X)</code>) forest. Defaults to <code>None</code>.</li> <li><code>drop_vars_tau</code> (<code>list</code> or <code>np.array</code>): Vector of variable names or column indices denoting variables that should be excluded from the treatment effect (<code>tau(X)</code>) forest. Defaults to <code>None</code>. If both <code>drop_vars_tau</code> and <code>keep_vars_tau</code> are set, <code>drop_vars_tau</code> will be ignored.</li> <li><code>drop_vars_variance</code> (<code>list</code> or <code>np.array</code>): Vector of variable names or column indices denoting variables that should be excluded from the variance (<code>sigma^2(X)</code>) forest. Defaults to <code>None</code>. If both <code>drop_vars_variance</code> and <code>keep_vars_variance</code> are set, <code>drop_vars_variance</code> will be ignored.</li> <li><code>keep_vars_variance</code> (<code>list</code> or <code>np.array</code>): Vector of variable names or column indices denoting variables that should be included in the variance (<code>sigma^2(X)</code>) forest. Defaults to <code>None</code>.</li> <li><code>num_trees_mu</code> (<code>int</code>): Number of trees in the prognostic forest. Defaults to <code>200</code>.</li> <li><code>num_trees_tau</code> (<code>int</code>): Number of trees in the treatment effect forest. Defaults to <code>50</code>.</li> <li><code>num_trees_variance</code> (<code>int</code>): Number of trees in the ensemble for the conditional variance model. Defaults to <code>0</code>. Variance is only modeled using a tree / forest if <code>num_trees_variance &gt; 0</code>.</li> <li><code>sample_sigma_global</code> (<code>bool</code>): Whether or not to update the <code>sigma^2</code> global error variance parameter based on <code>IG(a_global, b_global)</code>. Defaults to <code>True</code>.</li> <li><code>sample_sigma_leaf_mu</code> (<code>bool</code>): Whether or not to update the <code>tau</code> leaf scale variance parameter based on <code>IG(a_leaf, b_leaf)</code> for the prognostic forest.      Cannot (currently) be set to true if <code>basis_train</code> has more than one column. Defaults to <code>True</code>.</li> <li><code>sample_sigma_leaf_tau</code> (<code>bool</code>): Whether or not to update the <code>tau</code> leaf scale variance parameter based on <code>IG(a_leaf, b_leaf)</code> for the treatment effect forest.      Cannot (currently) be set to true if <code>basis_train</code> has more than one column. Defaults to <code>True</code>.</li> <li><code>propensity_covariate</code> (<code>str</code>): Whether to include the propensity score as a covariate in either or both of the forests. Enter <code>\"none\"</code> for neither, <code>\"mu\"</code> for the prognostic forest, <code>\"tau\"</code> for the treatment forest, and <code>\"both\"</code> for both forests.      If this is not <code>\"none\"</code> and a propensity score is not provided, it will be estimated from (<code>X_train</code>, <code>Z_train</code>) using <code>BARTModel</code>. Defaults to <code>\"mu\"</code>.</li> <li><code>adaptive_coding</code> (<code>bool</code>): Whether or not to use an \"adaptive coding\" scheme in which a binary treatment variable is not coded manually as (0,1) or (-1,1) but learned via      parameters <code>b_0</code> and <code>b_1</code> that attach to the outcome model <code>[b_0 (1-Z) + b_1 Z] tau(X)</code>. This is ignored when Z is not binary. Defaults to True.</li> <li><code>b_0</code> (<code>float</code>): Initial value of the \"control\" group coding parameter. This is ignored when <code>Z</code> is not binary. Default: <code>-0.5</code>.</li> <li><code>b_1</code> (<code>float</code>): Initial value of the \"treated\" group coding parameter. This is ignored when <code>Z</code> is not binary. Default: <code>0.5</code>.</li> <li><code>random_seed</code> (<code>int</code>): Integer parameterizing the C++ random number generator. If not specified, the C++ random number generator is seeded according to <code>std::random_device</code>.</li> <li><code>keep_burnin</code> (<code>bool</code>): Whether or not \"burnin\" samples should be included in predictions. Defaults to <code>False</code>. Ignored if <code>num_mcmc == 0</code>.</li> <li><code>keep_gfr</code> (<code>bool</code>): Whether or not \"warm-start\" / grow-from-root samples should be included in predictions. Defaults to <code>False</code>. Ignored if <code>num_mcmc == 0</code>.</li> <li><code>keep_every</code> (<code>int</code>): How many iterations of the burned-in MCMC sampler should be run before forests and parameters are retained. Defaults to <code>1</code>. Setting <code>keep_every = k</code> for some <code>k &gt; 1</code> will \"thin\" the MCMC samples by retaining every <code>k</code>-th sample, rather than simply every sample. This can reduce the autocorrelation of the MCMC samples.</li> </ul> <code>None</code>"},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel.predict_tau","title":"<code>predict_tau(X, Z, propensity=None)</code>","text":"<p>Predict CATE function for every provided observation.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array or DataFrame</code> <p>Test set covariates.</p> required <code>Z</code> <code>array</code> <p>Test set treatment indicators.</p> required <code>propensity</code> <code>array</code> <p>Optional test set propensities. Must be provided if propensities were provided when the model was sampled.</p> <code>None</code> <p>Returns:</p> Type Description <code>array</code> <p>Array with as many rows as in <code>X</code> and as many columns as retained samples of the algorithm.</p>"},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel.predict_variance","title":"<code>predict_variance(covariates, propensity=None)</code>","text":"<p>Predict expected conditional variance from a BART model.</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array</code> <p>Test set covariates.</p> required <code>propensity</code> <code>array</code> <p>Test set propensity scores. Optional (not currently used in variance forests).</p> <code>None</code> <p>Returns:</p> Type Description <code>array</code> <p>Array of predictions corresponding to the variance forest. Each array will contain as many rows as in <code>covariates</code> and as many columns as retained samples of the algorithm.</p>"},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel.predict","title":"<code>predict(X, Z, propensity=None)</code>","text":"<p>Predict outcome model components (CATE function and prognostic function) as well as overall outcome for every provided observation.  Predicted outcomes are computed as <code>yhat = mu_x + Z*tau_x</code> where mu_x is a sample of the prognostic function and tau_x is a sample of the treatment effect (CATE) function.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array or DataFrame</code> <p>Test set covariates.</p> required <code>Z</code> <code>array</code> <p>Test set treatment indicators.</p> required <code>propensity</code> <code>`np.array`</code> <p>Optional test set propensities. Must be provided if propensities were provided when the model was sampled.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tau_x</code> <code>array</code> <p>Conditional average treatment effect (CATE) samples for every observation provided.</p> <code>mu_x</code> <code>array</code> <p>Prognostic effect samples for every observation provided.</p> <code>yhat_x</code> <code>array</code> <p>Outcome prediction samples for every observation provided.</p> <code>sigma2_x</code> <code>(array, optional)</code> <p>Variance forest samples for every observation provided. Only returned if the  model includes a heteroskedasticity forest.</p>"},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel.to_json","title":"<code>to_json()</code>","text":"<p>Converts a sampled BART model to JSON string representation (which can then be saved to a file or  processed using the <code>json</code> library)</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON string representing model metadata (hyperparameters), sampled parameters, and sampled forests</p>"},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel.from_json","title":"<code>from_json(json_string)</code>","text":"<p>Converts a JSON string to an in-memory BART model.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representing model metadata (hyperparameters), sampled parameters, and sampled forests</p> required"},{"location":"python_docs/api/bcf.html#stochtree.bcf.BCFModel.is_sampled","title":"<code>is_sampled()</code>","text":"<p>Whether or not a BCF model has been sampled.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if a BCF model has been sampled, <code>False</code> otherwise</p>"},{"location":"python_docs/api/low-level/index.html","title":"Low-Level API","text":"<p>In addition to high-level samplers for BART and BCF,  the <code>stochtree</code> Python library provides direct access to many of the computational structures that  underlie stochastic tree algorithms: tree ensembles, sampling algorithms, and \"tracking\" data structures  that enable the algorithms to work effectively. This interface consists of:</p> <ol> <li>Data API: loading and storing in-memory data needed to train <code>stochtree</code> models.</li> <li>Forest API: creating, storing, and modifying ensembles of decision trees that underlie all <code>stochtree</code> models.</li> <li>Sampler API: sampling from stochastic tree ensemble models as well as several supported parametric models.</li> <li>Utilities API: seeding a C++ random number generator, preprocessing data, and serializing models to JSON (files or in-memory strings).</li> </ol>"},{"location":"python_docs/api/low-level/dataset.html","title":"Data API","text":""},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Dataset","title":"<code>stochtree.data.Dataset()</code>","text":"<p>Wrapper around a C++ class that stores all of the non-outcome data used in <code>stochtree</code>. This includes:</p> <ol> <li>Features used for partitioning (also referred to as \"covariates\" in many places in these docs).</li> <li>Basis vectors used to define non-constant leaf models. This is optional but may be included via the <code>add_basis</code> method.</li> <li>Variance weights used to define heteroskedastic or otherwise weighted models. This is optional but may be included via the <code>add_variance_weights</code> method.</li> </ol>"},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Dataset.add_covariates","title":"<code>add_covariates(covariates)</code>","text":"<p>Add covariates to a dataset</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array</code> <p>Numpy array of covariates. If data contain categorical, string, time series, or other columns in a  dataframe, please first preprocess using the <code>CovariateTransformer</code>.</p> required"},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Dataset.add_basis","title":"<code>add_basis(basis)</code>","text":"<p>Add basis matrix to a dataset</p> <p>Parameters:</p> Name Type Description Default <code>basis</code> <code>array</code> <p>Numpy array of basis vectors.</p> required"},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Dataset.update_basis","title":"<code>update_basis(basis)</code>","text":"<p>Update basis matrix in a dataset. Allows users to build an ensemble whose leaves  regress on bases that are updated throughout the sampler.</p> <p>Parameters:</p> Name Type Description Default <code>basis</code> <code>array</code> <p>Numpy array of basis vectors.</p> required"},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Dataset.add_variance_weights","title":"<code>add_variance_weights(variance_weights)</code>","text":"<p>Add variance weights to a dataset</p> <p>Parameters:</p> Name Type Description Default <code>variance_weights</code> <code>array</code> <p>Univariate numpy array of variance weights.</p> required"},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Residual","title":"<code>stochtree.data.Residual(residual)</code>","text":"<p>Wrapper around a C++ class that stores residual data used in <code>stochtree</code>.  This object becomes part of the real-time model \"state\" in that its contents  always contain a full or partial residual, depending on the state of the sampler.</p> <p>Typically this object is initialized with the original outcome and then \"residualized\"  by subtracting out the initial prediction value of every tree in every forest term  (as well as the predictions of any other model term).</p> <p>Parameters:</p> Name Type Description Default <code>residual</code> <code>array</code> <p>Univariate numpy array of residual values.</p> required"},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Residual.get_residual","title":"<code>get_residual()</code>","text":"<p>Extract the current values of the residual as a numpy array</p> <p>Returns:</p> Type Description <code>array</code> <p>Current values of the residual (which may be net of any forest / other model terms)</p>"},{"location":"python_docs/api/low-level/dataset.html#stochtree.data.Residual.update_data","title":"<code>update_data(new_vector)</code>","text":"<p>Update the current state of the outcome (i.e. partial residual) data by replacing each element with the elements of <code>new_vector</code></p> <p>Parameters:</p> Name Type Description Default <code>new_vector</code> <code>array</code> <p>Univariate numpy array of new residual values.</p> required"},{"location":"python_docs/api/low-level/forest.html","title":"Forest API","text":""},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest","title":"<code>stochtree.forest.Forest</code>","text":"<p>In-memory python wrapper around a C++ tree ensemble object</p> <p>Parameters:</p> Name Type Description Default <code>num_trees</code> <code>int</code> <p>Number of trees that each forest should contain</p> required <code>output_dimension</code> <code>int</code> <p>Dimension of the leaf node parameters in each tree</p> <code>1</code> <code>leaf_constant</code> <code>bool</code> <p>Whether the leaf node model is \"constant\" (i.e. prediction is simply a  sum of leaf node parameters for every observation in a dataset) or not (i.e.  each leaf node parameter is multiplied by a \"basis vector\" before being returned  as a prediction).</p> <code>True</code> <code>is_exponentiated</code> <code>bool</code> <p>Whether or not the leaf node parameters are stored in log scale (in which case, they  must be exponentiated before being returned as predictions).</p> <code>False</code>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.reset_root","title":"<code>reset_root()</code>","text":"<p>Reset forest to a forest with all single node (i.e. \"root\") trees</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.reset","title":"<code>reset(forest_container, forest_num)</code>","text":"<p>Reset forest to the forest indexed by <code>forest_num</code> in <code>forest_container</code></p> <p>Parameters:</p> Name Type Description Default <code>forest_container</code> <code>`ForestContainer</code> <p>Stochtree object storing tree ensembles</p> required <code>forest_num</code> <code>int</code> <p>Index of the ensemble used to reset the <code>Forest</code></p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.predict","title":"<code>predict(dataset)</code>","text":"<p>Predict from each forest in the container, using the provided <code>Dataset</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Python object wrapping the \"dataset\" class used by C++ sampling and prediction data structures.</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array with length equal to the number of observations in <code>dataset</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.predict_raw","title":"<code>predict_raw(dataset)</code>","text":"<p>Predict raw leaf values for a every forest in the container, using the provided <code>Dataset</code> object</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Python object wrapping the \"dataset\" class used by C++ sampling and prediction data structures.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Numpy array with (<code>n</code>, <code>k</code>) dimensions, where <code>n</code> is the number of observations in <code>dataset</code> and <code>k</code> is the dimension of the leaf parameter. If <code>k = 1</code>, then the returned array is simply one-dimensional  with <code>n</code> observations.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.set_root_leaves","title":"<code>set_root_leaves(leaf_value)</code>","text":"<p>Set constant (root) leaf node values for every tree in the forest.  Assumes the forest consists of all root (single-node) trees.</p> <p>Parameters:</p> Name Type Description Default <code>leaf_value</code> <code>float or array</code> <p>Constant values to which root nodes are to be set. If the trees in forest <code>forest_num</code>  are univariate, then <code>leaf_value</code> must be a <code>float</code>, while if the trees in forest <code>forest_num</code>  are multivariate, then <code>leaf_value</code> must be a <code>np.array</code>.</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.add_numeric_split","title":"<code>add_numeric_split(tree_num, leaf_num, feature_num, split_threshold, left_leaf_value, right_leaf_value)</code>","text":"<p>Add a numeric (i.e. X[,i] &lt;= c) split to a given tree in the forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be split</p> required <code>leaf_num</code> <code>int</code> <p>Leaf to be split</p> required <code>feature_num</code> <code>int</code> <p>Feature that defines the new split</p> required <code>split_threshold</code> <code>float</code> <p>Value that defines the cutoff of the new split</p> required <code>left_leaf_value</code> <code>float or array</code> <p>Value (or array of values) to assign to the newly created left node</p> required <code>right_leaf_value</code> <code>float or array</code> <p>Value (or array of values) to assign to the newly created right node</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.get_tree_leaves","title":"<code>get_tree_leaves(tree_num)</code>","text":"<p>Retrieve a vector of indices of leaf nodes for a given tree in the forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>float or array</code> <p>Index of the tree for which leaf indices will be retrieved</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array, containing the indices of leaf nodes in a given tree.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.get_tree_split_counts","title":"<code>get_tree_split_counts(tree_num, num_features)</code>","text":"<p>Retrieve a vector of split counts for every training set variable in a given tree in the forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree for which split counts will be retrieved</p> required <code>num_features</code> <code>int</code> <p>Total number of features in the training set</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array with as many elements as in the forest model's training set,  containing the split count for each feature for a given tree of the forest.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.get_overall_split_counts","title":"<code>get_overall_split_counts(num_features)</code>","text":"<p>Retrieve a vector of split counts for every training set variable in the forest</p> <p>Parameters:</p> Name Type Description Default <code>num_features</code> <code>int</code> <p>Total number of features in the training set</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array with as many elements as in the forest model's training set,  containing the overall split count in the forest for each feature.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.get_granular_split_counts","title":"<code>get_granular_split_counts(num_features)</code>","text":"<p>Retrieve a vector of split counts for every training set variable in the forest, reported separately for each tree</p> <p>Parameters:</p> Name Type Description Default <code>num_features</code> <code>int</code> <p>Total number of features in the training set</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array with as many elements as in the forest model's training set,  containing the split count for each feature for a every tree in the forest.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.num_forest_leaves","title":"<code>num_forest_leaves()</code>","text":"<p>Return the total number of leaves in a forest</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of leaves in a forest</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.sum_leaves_squared","title":"<code>sum_leaves_squared()</code>","text":"<p>Return the total sum of squared leaf values in a forest</p> <p>Returns:</p> Type Description <code>float</code> <p>Sum of squared leaf values in a forest</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.is_leaf_node","title":"<code>is_leaf_node(tree_num, node_id)</code>","text":"<p>Whether or not a given node of a given tree of a forest is a leaf</p> <p>tree_num : int     Index of the tree to be queried node_id : int     Index of the node to be queried</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if node <code>node_id</code> in tree <code>tree_num</code> is a leaf, <code>False</code> otherwise</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.is_numeric_split_node","title":"<code>is_numeric_split_node(tree_num, node_id)</code>","text":"<p>Whether or not a given node of a given tree of a forest is a numeric split node</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if node <code>node_id</code> in tree <code>tree_num</code> is a numeric split node, <code>False</code> otherwise</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.is_categorical_split_node","title":"<code>is_categorical_split_node(tree_num, node_id)</code>","text":"<p>Whether or not a given node of a given tree of a forest is a categorical split node</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if node <code>node_id</code> in tree <code>tree_num</code> is a categorical split node, <code>False</code> otherwise</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.parent_node","title":"<code>parent_node(tree_num, node_id)</code>","text":"<p>Parent node of given node of a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Index of the parent of node <code>node_id</code> in tree <code>tree_num</code>.  If <code>node_id</code> is a root node, returns <code>-1</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.left_child_node","title":"<code>left_child_node(tree_num, node_id)</code>","text":"<p>Left child node of given node of a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Index of the left child of node <code>node_id</code> in tree <code>tree_num</code>.  If <code>node_id</code> is a leaf, returns <code>-1</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.right_child_node","title":"<code>right_child_node(tree_num, node_id)</code>","text":"<p>Right child node of given node of a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Index of the right child of node <code>node_id</code> in tree <code>tree_num</code>.  If <code>node_id</code> is a leaf, returns <code>-1</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.node_depth","title":"<code>node_depth(tree_num, node_id)</code>","text":"<p>Depth of given node of a given tree of a forest Returns <code>-1</code> if the node is a leaf.</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Depth of node <code>node_id</code> in tree <code>tree_num</code>. The root node is defined as \"depth zero.\"</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.node_split_index","title":"<code>node_split_index(tree_num, node_id)</code>","text":"<p>Split index of given node of a given tree of a forest.  Returns <code>-1</code> if the node is a leaf.</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Split index of <code>node_id</code> in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.node_split_threshold","title":"<code>node_split_threshold(tree_num, node_id)</code>","text":"<p>Threshold that defines a numeric split for a given node of a given tree of a forest.  Returns <code>np.Inf</code> if the node is a leaf or a categorical split node.</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>float</code> <p>Threshold that defines a numeric split for node <code>node_id</code> in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.node_split_categories","title":"<code>node_split_categories(tree_num, node_id)</code>","text":"<p>Array of category indices that define a categorical split for a given node of a given tree of a forest.  Returns <code>np.array([np.Inf])</code> if the node is a leaf or a numeric split node.</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of category indices that define a categorical split for node <code>node_id</code> in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.node_leaf_values","title":"<code>node_leaf_values(tree_num, node_id)</code>","text":"<p>Leaf node value(s) for a given node of a given tree of a forest.  Values are stale if the node is a split node.</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of parameter values for node <code>node_id</code> in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.num_nodes","title":"<code>num_nodes(tree_num)</code>","text":"<p>Number of nodes in a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of nodes in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.num_leaves","title":"<code>num_leaves(tree_num)</code>","text":"<p>Number of leaves in a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of leaves in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.num_leaf_parents","title":"<code>num_leaf_parents(tree_num)</code>","text":"<p>Number of leaf parents in a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of leaf parents in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.num_split_nodes","title":"<code>num_split_nodes(tree_num)</code>","text":"<p>Number of split_nodes in a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of split nodes in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.nodes","title":"<code>nodes(tree_num)</code>","text":"<p>Array of node indices in a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of indices of nodes in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.Forest.leaves","title":"<code>leaves(tree_num)</code>","text":"<p>Array of leaf indices in a given tree of a forest</p> <p>Parameters:</p> Name Type Description Default <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of indices of leaf nodes in tree <code>tree_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer","title":"<code>stochtree.forest.ForestContainer</code>","text":"<p>Container that stores sampled (and retained) tree ensembles from BART, BCF or a custom sampler.</p> <p>Parameters:</p> Name Type Description Default <code>num_trees</code> <code>int</code> <p>Number of trees that each forest should contain</p> required <code>output_dimension</code> <code>int</code> <p>Dimension of the leaf node parameters in each tree</p> <code>1</code> <code>leaf_constant</code> <code>bool</code> <p>Whether the leaf node model is \"constant\" (i.e. prediction is simply a  sum of leaf node parameters for every observation in a dataset) or not (i.e.  each leaf node parameter is multiplied by a \"basis vector\" before being returned  as a prediction).</p> <code>True</code> <code>is_exponentiated</code> <code>bool</code> <p>Whether or not the leaf node parameters are stored in log scale (in which case, they  must be exponentiated before being returned as predictions).</p> <code>False</code>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.predict","title":"<code>predict(dataset)</code>","text":"<p>Predict from each forest in the container, using the provided <code>Dataset</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Python object wrapping the \"dataset\" class used by C++ sampling and prediction data structures.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Numpy array with (<code>n</code>, <code>m</code>) dimensions, where <code>n</code> is the number of observations in <code>dataset</code> and <code>m</code>  is the number of samples in the forest container.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.predict_raw","title":"<code>predict_raw(dataset)</code>","text":"<p>Predict raw leaf values for a every forest in the container, using the provided <code>Dataset</code> object</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Python object wrapping the \"dataset\" class used by C++ sampling and prediction data structures.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Numpy array with (<code>n</code>, <code>k</code>, <code>m</code>) dimensions, where <code>n</code> is the number of observations in <code>dataset</code>, <code>k</code> is the dimension of the leaf parameter, and <code>m</code> is the number of samples in the forest container. If <code>k = 1</code>, then the returned array is simply (<code>n</code>, <code>m</code>) dimensions.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.predict_raw_single_forest","title":"<code>predict_raw_single_forest(dataset, forest_num)</code>","text":"<p>Predict raw leaf values for a specific forest (indexed by <code>forest_num</code>), using the provided <code>Dataset</code> object</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Python object wrapping the \"dataset\" class used by C++ sampling and prediction data structures.</p> required <code>forest_num</code> <code>int</code> <p>Index of the forest from which to predict. Forest indices are 0-based.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Numpy array with (<code>n</code>, <code>k</code>) dimensions, where <code>n</code> is the number of observations in <code>dataset</code> and <code>k</code> is the dimension of the leaf parameter.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.predict_raw_single_tree","title":"<code>predict_raw_single_tree(dataset, forest_num, tree_num)</code>","text":"<p>Predict raw leaf values for a specific tree of a specific forest (indexed by <code>tree_num</code> and <code>forest_num</code>  respectively), using the provided <code>Dataset</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Python object wrapping the \"dataset\" class used by C++ sampling and prediction data structures.</p> required <code>forest_num</code> <code>int</code> <p>Index of the forest from which to predict. Forest indices are 0-based.</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree which to predict (within forest indexed by <code>forest_num</code>). Tree indices are 0-based.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Numpy array with (<code>n</code>, <code>k</code>) dimensions, where <code>n</code> is the number of observations in <code>dataset</code> and <code>k</code> is the dimension of the leaf parameter.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.set_root_leaves","title":"<code>set_root_leaves(forest_num, leaf_value)</code>","text":"<p>Set constant (root) leaf node values for every tree in the forest indexed by <code>forest_num</code>.  Assumes the forest consists of all root (single-node) trees.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest for which we will set root node parameters.</p> required <code>leaf_value</code> <code>float or array</code> <p>Constant values to which root nodes are to be set. If the trees in forest <code>forest_num</code>  are univariate, then <code>leaf_value</code> must be a <code>float</code>, while if the trees in forest <code>forest_num</code>  are multivariate, then <code>leaf_value</code> must be a <code>np.array</code>.</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.save_to_json_file","title":"<code>save_to_json_file(json_filename)</code>","text":"<p>Save the forests in the container to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_filename</code> <code>str</code> <p>Name of JSON file to which forest container state will be saved.  May contain absolute or relative paths.</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.load_from_json_file","title":"<code>load_from_json_file(json_filename)</code>","text":"<p>Load a forest container from output stored in a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_filename</code> <code>str</code> <p>Name of JSON file from which forest container state will be restored.  May contain absolute or relative paths.</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.dump_json_string","title":"<code>dump_json_string()</code>","text":"<p>Dump a forest container into an in-memory JSON string (which can be directly serialized or  combined with other JSON strings before serialization).</p> <p>Returns:</p> Type Description <code>str</code> <p>In-memory string containing state of a forest container.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.load_from_json_string","title":"<code>load_from_json_string(json_string)</code>","text":"<p>Reload a forest container from an in-memory JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>In-memory string containing state of a forest container.</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.add_sample","title":"<code>add_sample(leaf_value)</code>","text":"<p>Add a new all-root ensemble to the container, with all of the leaves set to the value / vector provided</p> <p>Parameters:</p> Name Type Description Default <code>leaf_value</code> <code>float or array</code> <p>Value (or vector of values) to initialize root nodes of every tree in a forest</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.add_numeric_split","title":"<code>add_numeric_split(forest_num, tree_num, leaf_num, feature_num, split_threshold, left_leaf_value, right_leaf_value)</code>","text":"<p>Add a numeric (i.e. X[,i] &lt;= c) split to a given tree in the ensemble</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest which contains the tree to be split</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be split</p> required <code>leaf_num</code> <code>int</code> <p>Leaf to be split</p> required <code>feature_num</code> <code>int</code> <p>Feature that defines the new split</p> required <code>split_threshold</code> <code>float</code> <p>Value that defines the cutoff of the new split</p> required <code>left_leaf_value</code> <code>float or array</code> <p>Value (or array of values) to assign to the newly created left node</p> required <code>right_leaf_value</code> <code>float or array</code> <p>Value (or array of values) to assign to the newly created right node</p> required"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.get_tree_leaves","title":"<code>get_tree_leaves(forest_num, tree_num)</code>","text":"<p>Retrieve a vector of indices of leaf nodes for a given tree in a given forest</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest which contains tree <code>tree_num</code></p> required <code>tree_num</code> <code>float or array</code> <p>Index of the tree for which leaf indices will be retrieved</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array, containing the indices of leaf nodes in a given tree.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.get_tree_split_counts","title":"<code>get_tree_split_counts(forest_num, tree_num, num_features)</code>","text":"<p>Retrieve a vector of split counts for every training set feature in a given tree in a given forest</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest which contains tree <code>tree_num</code></p> required <code>tree_num</code> <code>int</code> <p>Index of the tree for which split counts will be retrieved</p> required <code>num_features</code> <code>int</code> <p>Total number of features in the training set</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array with as many elements as in the forest model's training set,  containing the split count for each feature for a given forest and tree.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.get_forest_split_counts","title":"<code>get_forest_split_counts(forest_num, num_features)</code>","text":"<p>Retrieve a vector of split counts for every training set feature in a given forest</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest which contains tree <code>tree_num</code></p> required <code>num_features</code> <code>int</code> <p>Total number of features in the training set</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array with as many elements as in the forest model's training set,  containing the split count for each feature for a given forest (summed across every tree in the forest).</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.get_overall_split_counts","title":"<code>get_overall_split_counts(num_features)</code>","text":"<p>Retrieve a vector of split counts for every training set feature, aggregated across ensembles and trees.</p> <p>Parameters:</p> Name Type Description Default <code>num_features</code> <code>int</code> <p>Total number of features in the training set</p> required <p>Returns:</p> Type Description <code>array</code> <p>One-dimensional numpy array with as many elements as in the forest model's training set,  containing the split count for each feature summed across every forest of every tree in the container.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.get_granular_split_counts","title":"<code>get_granular_split_counts(num_features)</code>","text":"<p>Retrieve a vector of split counts for every training set variable in a given forest, reported separately for each ensemble and tree</p> <p>Parameters:</p> Name Type Description Default <code>num_features</code> <code>int</code> <p>Total number of features in the training set</p> required <p>Returns:</p> Type Description <code>array</code> <p>Three-dimensional numpy array, containing the number of splits a variable receives in each tree of each forest in a <code>ForestContainer</code>. Array will have dimensions (<code>m</code>,<code>b</code>,<code>p</code>) where <code>m</code> is the number of forests in the container, <code>b</code> is the number of trees in each  forest, and <code>p</code> is the number of features in the forest model's training dataset.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.num_forest_leaves","title":"<code>num_forest_leaves(forest_num)</code>","text":"<p>Return the total number of leaves for a given forest in the <code>ForestContainer</code></p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Number of leaves in a given forest in a <code>ForestContainer</code></p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.sum_leaves_squared","title":"<code>sum_leaves_squared(forest_num)</code>","text":"<p>Return the total sum of squared leaf values for a given forest in the <code>ForestContainer</code></p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <p>Returns:</p> Type Description <code>float</code> <p>Sum of squared leaf values in a given forest in a <code>ForestContainer</code></p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.is_leaf_node","title":"<code>is_leaf_node(forest_num, tree_num, node_id)</code>","text":"<p>Whether or not a given node of a given tree in a given forest in the <code>ForestContainer</code> is a leaf</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code> is a leaf, <code>False</code> otherwise</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.is_numeric_split_node","title":"<code>is_numeric_split_node(forest_num, tree_num, node_id)</code>","text":"<p>Whether or not a given node of a given tree in a given forest in the <code>ForestContainer</code> is a numeric split node</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code> is a numeric split node, <code>False</code> otherwise</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.is_categorical_split_node","title":"<code>is_categorical_split_node(forest_num, tree_num, node_id)</code>","text":"<p>Whether or not a given node of a given tree in a given forest in the <code>ForestContainer</code> is a categorical split node</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code> is a categorical split node, <code>False</code> otherwise</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.parent_node","title":"<code>parent_node(forest_num, tree_num, node_id)</code>","text":"<p>Parent node of given node of a given tree in a given forest in the <code>ForestContainer</code></p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Index of the parent of node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>.  If <code>node_id</code> is a root node, returns <code>-1</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.left_child_node","title":"<code>left_child_node(forest_num, tree_num, node_id)</code>","text":"<p>Left child node of given node of a given tree in a given forest in the <code>ForestContainer</code></p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Index of the left child of node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>.  If <code>node_id</code> is a leaf, returns <code>-1</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.right_child_node","title":"<code>right_child_node(forest_num, tree_num, node_id)</code>","text":"<p>Right child node of given node of a given tree in a given forest in the <code>ForestContainer</code></p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Index of the right child of node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>.  If <code>node_id</code> is a leaf, returns <code>-1</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.node_depth","title":"<code>node_depth(forest_num, tree_num, node_id)</code>","text":"<p>Depth of given node of a given tree in a given forest in the <code>ForestContainer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Depth of node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>. The root node is defined  as \"depth zero.\"</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.node_split_index","title":"<code>node_split_index(forest_num, tree_num, node_id)</code>","text":"<p>Split index of given node of a given tree in a given forest in the <code>ForestContainer</code>. Returns <code>-1</code> if the node is a leaf.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Split index of <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.node_split_threshold","title":"<code>node_split_threshold(forest_num, tree_num, node_id)</code>","text":"<p>Threshold that defines a numeric split for a given node of a given tree in a given forest in the <code>ForestContainer</code>. Returns <code>np.Inf</code> if the node is a leaf or a categorical split node.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>float</code> <p>Threshold that defines a numeric split for node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.node_split_categories","title":"<code>node_split_categories(forest_num, tree_num, node_id)</code>","text":"<p>Array of category indices that define a categorical split for a given node of a given tree in a given forest in the <code>ForestContainer</code>. Returns <code>np.array([np.Inf])</code> if the node is a leaf or a numeric split node.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of category indices that define a categorical split for node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.node_leaf_values","title":"<code>node_leaf_values(forest_num, tree_num, node_id)</code>","text":"<p>Node parameter value(s) for a given node of a given tree in a given forest in the <code>ForestContainer</code>. Values are stale if the node is a split node.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <code>node_id</code> <code>int</code> <p>Index of the node to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of parameter values for node <code>node_id</code> in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.num_nodes","title":"<code>num_nodes(forest_num, tree_num)</code>","text":"<p>Number of nodes in a given tree in a given forest in the <code>ForestContainer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of nodes in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.num_leaves","title":"<code>num_leaves(forest_num, tree_num)</code>","text":"<p>Number of leaves in a given tree in a given forest in the <code>ForestContainer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of leaves in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.num_leaf_parents","title":"<code>num_leaf_parents(forest_num, tree_num)</code>","text":"<p>Number of leaf parents (split nodes with two leaves as children) in a given tree in a given forest in the <code>ForestContainer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of leaf parents in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.num_split_nodes","title":"<code>num_split_nodes(forest_num, tree_num)</code>","text":"<p>Number of split_nodes in a given tree in a given forest in the <code>ForestContainer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of split nodes in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.nodes","title":"<code>nodes(forest_num, tree_num)</code>","text":"<p>Array of node indices in a given tree in a given forest in the <code>ForestContainer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of indices of nodes in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.leaves","title":"<code>leaves(forest_num, tree_num)</code>","text":"<p>Array of leaf indices in a given tree in a given forest in the <code>ForestContainer</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be queried</p> required <code>tree_num</code> <code>int</code> <p>Index of the tree to be queried</p> required <p>Returns:</p> Type Description <code>array</code> <p>Array of indices of leaf nodes in tree <code>tree_num</code> of forest <code>forest_num</code>.</p>"},{"location":"python_docs/api/low-level/forest.html#stochtree.forest.ForestContainer.delete_sample","title":"<code>delete_sample(forest_num)</code>","text":"<p>Modify the <code>ForestContainer</code> by removing the forest sample indexed by <code>forest_num</code>.</p> <p>Parameters:</p> Name Type Description Default <code>forest_num</code> <code>int</code> <p>Index of the forest to be removed from the <code>ForestContainer</code></p> required"},{"location":"python_docs/api/low-level/sampler.html","title":"Sampler API","text":""},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler","title":"<code>stochtree.sampler.ForestSampler</code>","text":"<p>Wrapper around many of the core C++ sampling data structures and algorithms.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p><code>stochtree</code> dataset object storing covariates / bases / weights</p> required <code>feature_types</code> <code>array</code> <p>Array of integer-coded values indicating the column type of each feature in <code>dataset</code>.  Integer codes map <code>0</code> to \"numeric\" (continuous), <code>1</code> to \"ordered categorical, and <code>2</code> to  \"unordered categorical\".</p> required <code>num_trees</code> <code>int</code> <p>Number of trees in the forest model that this sampler class will fit.</p> required <code>num_obs</code> <code>int</code> <p>Number of observations / \"rows\" in <code>dataset</code>.</p> required <code>alpha</code> <code>float</code> <p>Prior probability of splitting for a tree of depth 0 in a forest model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>.</p> required <code>beta</code> <code>float</code> <p>Exponent that decreases split probabilities for nodes of depth &gt; 0 in a forest model. Tree split prior combines <code>alpha</code> and <code>beta</code> via <code>alpha*(1+node_depth)^-beta</code>.</p> required <code>min_samples_leaf</code> <code>int</code> <p>Minimum allowable size of a leaf, in terms of training samples, in a forest model.</p> required <code>max_depth</code> <code>int</code> <p>Maximum depth of any tree in the ensemble in a forest model.</p> <code>-1</code>"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.reconstitute_from_forest","title":"<code>reconstitute_from_forest(forest, dataset, residual, is_mean_model)</code>","text":"<p>Re-initialize a forest sampler tracking data structures from a specific forest in a <code>ForestContainer</code></p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p><code>stochtree</code> dataset object storing covariates / bases / weights</p> required <code>residual</code> <code>Residual</code> <p><code>stochtree</code> object storing continuously updated partial / full residual</p> required <code>forest</code> <code>Forest</code> <p><code>stochtree</code> object storing tree ensemble</p> required <code>is_mean_model</code> <code>bool</code> <p>Indicator of whether the model being updated a conditional mean model (<code>True</code>) or a conditional variance model (<code>False</code>)</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.sample_one_iteration","title":"<code>sample_one_iteration(forest_container, forest, dataset, residual, rng, feature_types, cutpoint_grid_size, leaf_model_scale_input, variable_weights, a_forest, b_forest, global_variance, leaf_model_int, keep_forest, gfr, pre_initialized)</code>","text":"<p>Sample one iteration of a forest using the specified model and tree sampling algorithm</p> <p>Parameters:</p> Name Type Description Default <code>forest_container</code> <code>ForestContainer</code> <p><code>stochtree</code> object storing tree ensembles</p> required <code>forest</code> <code>Forest</code> <p><code>stochtree</code> object storing the \"active\" forest being sampled</p> required <code>dataset</code> <code>Dataset</code> <p><code>stochtree</code> dataset object storing covariates / bases / weights</p> required <code>residual</code> <code>Residual</code> <p><code>stochtree</code> object storing continuously updated partial / full residual</p> required <code>rng</code> <code>RNG</code> <p><code>stochtree</code> object storing C++ random number generator to be used sampling algorithm</p> required <code>feature_types</code> <code>array</code> <p>Array of integer-coded feature types (0 = numeric, 1 = ordered categorical, 2 = unordered categorical)</p> required <code>cutpoint_grid_size</code> <code>int</code> <p>Maximum size of a grid of available cutpoints (which thins the number of possible splits, particularly useful in the grow-from-root algorithm)</p> required <code>leaf_model_scale_input</code> <code>array</code> <p>Numpy array containing leaf model scale parameter (if the leaf model is univariate, this is essentially a scalar which is used as such in the C++ source, but stored as a numpy array)</p> required <code>variable_weights</code> <code>array</code> <p>Numpy array containing sampling probabilities for each feature</p> required <code>a_forest</code> <code>float</code> <p>Shape parameter for the inverse gamma outcome model for a heteroskedasticity forest</p> required <code>b_forest</code> <code>float</code> <p>Scale parameter for the inverse gamma outcome model for a heteroskedasticity forest</p> required <code>global_variance</code> <code>float</code> <p>Current value of the global error variance parameter</p> required <code>leaf_model_int</code> <code>int</code> <p>Integer encoding the leaf model type (0 = constant Gaussian leaf mean model, 1 = univariate Gaussian leaf regression mean model, 2 = multivariate Gaussian leaf regression mean model, 3 = univariate Inverse Gamma constant leaf variance model)</p> required <code>keep_forest</code> <code>bool</code> <p>Whether or not the resulting forest should be retained in <code>forest_container</code> or discarded (due to burnin or thinning for example)</p> required <code>gfr</code> <code>bool</code> <p>Whether or not the \"grow-from-root\" (GFR) sampler is run (if this is <code>True</code> and <code>leaf_model_int=0</code> this is equivalent to XBART, if this is <code>FALSE</code> and <code>leaf_model_int=0</code> this is equivalent to the original BART)</p> required <code>pre_initialized</code> <code>bool</code> <p>Whether or not the forest being sampled has already been initialized</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.prepare_for_sampler","title":"<code>prepare_for_sampler(dataset, residual, forest, leaf_model, initial_values)</code>","text":"<p>Initialize forest and tracking data structures with constant root values before running a sampler</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p><code>stochtree</code> dataset object storing covariates / bases / weights</p> required <code>residual</code> <code>Residual</code> <p><code>stochtree</code> object storing continuously updated partial / full residual</p> required <code>forest</code> <code>Forest</code> <p><code>stochtree</code> object storing the \"active\" forest being sampled</p> required <code>leaf_model</code> <code>int</code> <p>Integer encoding the leaf model type</p> required <code>initial_values</code> <code>array</code> <p>Constant root node value(s) at which to initialize forest prediction (internally, it is divided by the number of trees and typically it is 0 for mean models and 1 for variance models).</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.adjust_residual","title":"<code>adjust_residual(dataset, residual, forest, requires_basis, add)</code>","text":"<p>Method that \"adjusts\" the residual used for training tree ensembles by either adding or subtracting the prediction of each tree to the existing residual. </p> <p>This is typically run just once at the beginning of a forest sampling algorithm --- after trees are initialized with constant root node predictions, their  root predictions are subtracted out of the residual.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p><code>stochtree</code> dataset object storing covariates / bases / weights</p> required <code>residual</code> <code>Residual</code> <p><code>stochtree</code> object storing continuously updated partial / full residual</p> required <code>forest</code> <code>Forest</code> <p><code>stochtree</code> object storing the \"active\" forest being sampled</p> required <code>requires_basis</code> <code>bool</code> <p>Whether or not the forest requires a basis dot product when predicting</p> required <code>add</code> <code>bool</code> <p>Whether the predictions of each tree are added (if <code>add=True</code>) or subtracted (<code>add=False</code>) from the outcome to form the new residual</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.propagate_basis_update","title":"<code>propagate_basis_update(dataset, residual, forest)</code>","text":"<p>Propagates basis update through to the (full/partial) residual by iteratively (a) adding back in the previous prediction of each tree, (b) recomputing predictions  for each tree (caching on the C++ side), (c) subtracting the new predictions from the residual.</p> <p>This is useful in cases where a basis (for e.g. leaf regression) is updated outside of a tree sampler (as with e.g. adaptive coding for binary treatment BCF).  Once a basis has been updated, the overall \"function\" represented by a tree model has changed and this should be reflected through to the residual before the  next sampling loop is run.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Stochtree dataset object storing covariates / bases / weights</p> required <code>residual</code> <code>Residual</code> <p>Stochtree object storing continuously updated partial / full residual</p> required <code>forest</code> <code>Forest</code> <p>Stochtree object storing the \"active\" forest being sampled</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.update_alpha","title":"<code>update_alpha(alpha)</code>","text":"<p>Update <code>alpha</code> in the tree prior</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float</code> <p>New value of <code>alpha</code> to be used</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.update_beta","title":"<code>update_beta(beta)</code>","text":"<p>Update <code>beta</code> in the tree prior</p> <p>Parameters:</p> Name Type Description Default <code>beta</code> <code>float</code> <p>New value of <code>beta</code> to be used</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.update_min_samples_leaf","title":"<code>update_min_samples_leaf(min_samples_leaf)</code>","text":"<p>Update <code>min_samples_leaf</code> in the tree prior</p> <p>Parameters:</p> Name Type Description Default <code>min_samples_leaf</code> <code>int</code> <p>New value of <code>min_samples_leaf</code> to be used</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.ForestSampler.update_max_depth","title":"<code>update_max_depth(max_depth)</code>","text":"<p>Update <code>max_depth</code> in the tree prior</p> <p>Parameters:</p> Name Type Description Default <code>max_depth</code> <code>int</code> <p>New value of <code>max_depth</code> to be used</p> required"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.GlobalVarianceModel","title":"<code>stochtree.sampler.GlobalVarianceModel</code>","text":"<p>Wrapper around methods / functions for sampling a \"global\" error variance model  with inverse gamma prior.</p>"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.GlobalVarianceModel.sample_one_iteration","title":"<code>sample_one_iteration(residual, rng, a, b)</code>","text":"<p>Sample one iteration of a global error variance parameter</p> <p>Parameters:</p> Name Type Description Default <code>residual</code> <code>Residual</code> <p><code>stochtree</code> object storing continuously updated partial / full residual</p> required <code>rng</code> <code>RNG</code> <p><code>stochtree</code> object storing C++ random number generator to be used sampling algorithm</p> required <code>a</code> <code>float</code> <p>Shape parameter for the inverse gamma error variance model</p> required <code>b</code> <code>float</code> <p>Scale parameter for the inverse gamma error variance model</p> required <p>Returns:</p> Type Description <code>float</code> <p>One draw from a Gibbs sampler for the error variance model, which depends  on the rest of the model only through the \"full\" residual stored in  a <code>Residual</code> object (net of predictions of any mean term such as a forest or  an additive parametric fixed / random effect term).</p>"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.LeafVarianceModel","title":"<code>stochtree.sampler.LeafVarianceModel</code>","text":"<p>Wrapper around methods / functions for sampling a \"leaf scale\" model for the variance term of a Gaussian  leaf model with inverse gamma prior.</p>"},{"location":"python_docs/api/low-level/sampler.html#stochtree.sampler.LeafVarianceModel.sample_one_iteration","title":"<code>sample_one_iteration(forest, rng, a, b)</code>","text":"<p>Sample one iteration of a forest leaf model's variance parameter (assuming a location-scale leaf model, most commonly <code>N(0, tau)</code>)</p> <p>Parameters:</p> Name Type Description Default <code>forest</code> <code>Forest</code> <p><code>stochtree</code> object storing the \"active\" forest being sampled</p> required <code>rng</code> <code>RNG</code> <p><code>stochtree</code> object storing C++ random number generator to be used sampling algorithm</p> required <code>a</code> <code>float</code> <p>Shape parameter for the inverse gamma leaf scale model</p> required <code>b</code> <code>float</code> <p>Scale parameter for the inverse gamma leaf scale model</p> required <p>Returns:</p> Type Description <code>float</code> <p>One draw from a Gibbs sampler for the leaf scale model, which depends  on the rest of the model only through its respective forest.</p>"},{"location":"python_docs/api/low-level/utilities.html","title":"Utilies API","text":""},{"location":"python_docs/api/low-level/utilities.html#stochtree.sampler.RNG","title":"<code>stochtree.sampler.RNG</code>","text":"<p>Wrapper around the C++ standard library random number generator.  Accepts an optional random seed at initialization for replicability.</p> <p>Parameters:</p> Name Type Description Default <code>random_seed</code> <code>int</code> <p>Random seed for replicability. If not specified, the default value of <code>-1</code>  triggers an initialization of the RNG based on  std::random_device.</p> <code>-1</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.preprocessing.CovariateTransformer","title":"<code>stochtree.preprocessing.CovariateTransformer</code>","text":"<p>Class that transforms covariates to a format that can be used to define tree splits.  Modeled after the scikit-learn preprocessing classes.</p>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.preprocessing.CovariateTransformer.fit","title":"<code>fit(covariates)</code>","text":"<p>Fits a <code>CovariateTransformer</code> by unpacking (and storing) data type information on the input (raw) covariates and then converting to a numpy array which can be passed to a tree ensemble sampler.</p> <p>If <code>covariates</code> is a <code>pd.DataFrame</code>, column dtypes  will be handled as follows:</p> <ul> <li><code>category</code>: one-hot encoded if unordered, ordinal encoded if ordered</li> <li><code>string</code>: one-hot encoded</li> <li><code>boolean</code>: passed through as binary integer, treated as ordered categorical by tree samplers</li> <li>integer (i.e. <code>Int8</code>, <code>Int16</code>, etc...): passed through as double (note: if you have categorical data stored as integers, you should explicitly convert it to categorical in pandas, see this user guide)</li> <li>float (i.e. <code>Float32</code>, <code>Float64</code>): passed through as double</li> <li><code>object</code>: currently unsupported, convert object columns to numeric or categorical before passing</li> <li>Datetime (i.e. <code>datetime64</code>): currently unsupported, though datetime columns can be converted to numeric features, see here</li> <li>Period (i.e. <code>period[&lt;freq&gt;]</code>): currently unsupported, though period columns can be converted to numeric features, see here</li> <li>Interval (i.e. <code>interval</code>, <code>Interval[datetime64[ns]]</code>): currently unsupported, though interval columns can be converted to numeric or categorical features, see here</li> <li>Sparse (i.e. <code>Sparse</code>, <code>Sparse[float]</code>): currently unsupported, convert sparse columns to dense before passing</li> </ul> <p>Columns with unsupported types will be ignored, with a warning.</p> <p>If <code>covariates</code> is a <code>np.array</code>, columns must be numeric and the only preprocessing done by <code>CovariateTransformer.fit()</code> is to  auto-detect binary columns. All other integer-valued columns will be passed through to the tree sampler as (continuous) numeric data.  If you would like to treat integer-valued data as categorical, you can either convert your numpy array to a pandas dataframe and  explicitly tag such columns as ordered / unordered categorical, or preprocess manually using <code>sklearn.preprocessing.OneHotEncoder</code>  and <code>sklearn.preprocessing.OrdinalEncoder</code>.</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array or DataFrame</code> <p>Covariates to be preprocessed.</p> required"},{"location":"python_docs/api/low-level/utilities.html#stochtree.preprocessing.CovariateTransformer.transform","title":"<code>transform(covariates)</code>","text":"<p>Run a fitted a <code>CovariateTransformer</code> on a new covariate set,  returning a numpy array of covariates preprocessed into a format needed  to sample or predict from a <code>stochtree</code> ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array or DataFrame</code> <p>Covariates to be preprocessed.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Numpy array of preprocessed covariates, with as many rows as in <code>covariates</code>  and as many columns as were created during pre-processing (including one-hot encoding  categorical features).</p>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.preprocessing.CovariateTransformer.fit_transform","title":"<code>fit_transform(covariates)</code>","text":"<p>Runs the <code>fit()</code> and <code>transform()</code> methods in sequence.</p> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>array or DataFrame</code> <p>Covariates to be preprocessed.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Numpy array of preprocessed covariates, with as many rows as in <code>covariates</code>  and as many columns as were created during pre-processing (including one-hot encoding  categorical features).</p>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.preprocessing.CovariateTransformer.fetch_original_feature_indices","title":"<code>fetch_original_feature_indices()</code>","text":"<p>Map features in a preprocessed covariate set back to the  original set of features provided to a <code>CovariateTransformer</code>.</p> <p>Returns:</p> Type Description <code>list</code> <p>List with as many entries as features in the preprocessed results  returned by a fitted <code>CovariateTransformer</code>. Each element is a feature  index indicating the feature from which a given preprocessed feature was generated. If a single categorical feature were one-hot encoded into 5 binary features,  this method would return a list <code>[0,0,0,0,0]</code>. If the transformer merely passes through <code>k</code> numeric features, this method would return a list <code>[0,...,k-1]</code>.</p>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer","title":"<code>stochtree.serialization.JSONSerializer</code>","text":"<p>Class that handles serialization and deserialization of stochastic forest models</p>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.return_json_string","title":"<code>return_json_string()</code>","text":"<p>Convert JSON object to in-memory string</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON string representing model metadata (hyperparameters), sampled parameters, and sampled forests</p>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.load_from_json_string","title":"<code>load_from_json_string(json_string)</code>","text":"<p>Parse in-memory JSON string to <code>JsonCpp</code> object</p> <p>Parameters:</p> Name Type Description Default <code>json_string</code> <code>str</code> <p>JSON string representing model metadata (hyperparameters), sampled parameters, and sampled forests</p> required"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.add_forest","title":"<code>add_forest(forest_samples)</code>","text":"<p>Adds a container of forest samples to a json object</p> <p>Parameters:</p> Name Type Description Default <code>forest_samples</code> <code>ForestContainer</code> <p>Samples of a tree ensemble</p> required"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.add_scalar","title":"<code>add_scalar(field_name, field_value, subfolder_name=None)</code>","text":"<p>Adds a scalar (numeric) value to a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the numeric value will be stored</p> required <code>field_value</code> <code>float</code> <p>Numeric value to be stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> to be stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.add_boolean","title":"<code>add_boolean(field_name, field_value, subfolder_name=None)</code>","text":"<p>Adds a scalar (boolean) value to a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the boolean value will be stored</p> required <code>field_value</code> <code>bool</code> <p>Boolean value to be stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> to be stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.add_string","title":"<code>add_string(field_name, field_value, subfolder_name=None)</code>","text":"<p>Adds a string to a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the numeric value will be stored</p> required <code>field_value</code> <code>str</code> <p>String field to be stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> to be stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.add_numeric_vector","title":"<code>add_numeric_vector(field_name, field_vector, subfolder_name=None)</code>","text":"<p>Adds a numeric vector (stored as a numpy array) to a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the numeric vector will be stored</p> required <code>field_vector</code> <code>array</code> <p>Numpy array containing the vector to be stored in json. Should be one-dimensional.</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> to be stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.add_string_vector","title":"<code>add_string_vector(field_name, field_vector, subfolder_name=None)</code>","text":"<p>Adds a list of strings to a json object as an array</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the string list will be stored</p> required <code>field_vector</code> <code>list</code> <p>Python list of strings containing the array to be stored in json</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> to be stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.get_scalar","title":"<code>get_scalar(field_name, subfolder_name=None)</code>","text":"<p>Retrieves a scalar (numeric) value from a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the numeric value is stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> is stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.get_boolean","title":"<code>get_boolean(field_name, subfolder_name=None)</code>","text":"<p>Retrieves a scalar (boolean) value from a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the boolean value is stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> is stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.get_string","title":"<code>get_string(field_name, subfolder_name=None)</code>","text":"<p>Retrieve a string to a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the numeric value is stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> is stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.get_numeric_vector","title":"<code>get_numeric_vector(field_name, subfolder_name=None)</code>","text":"<p>Adds a string to a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the numeric vector is stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> to be stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.get_string_vector","title":"<code>get_string_vector(field_name, subfolder_name=None)</code>","text":"<p>Adds a string to a json object</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the json field / label under which the string list is stored</p> required <code>subfolder_name</code> <code>str</code> <p>Name of \"subfolder\" under which <code>field_name</code> to be stored in the json hierarchy</p> <code>None</code>"},{"location":"python_docs/api/low-level/utilities.html#stochtree.serialization.JSONSerializer.get_forest_container","title":"<code>get_forest_container(forest_str)</code>","text":"<p>Converts a JSON string for a container of forests to a <code>ForestContainer</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>forest_str</code> <code>str</code> <p>String containing the JSON representation of a <code>ForestContainer</code></p> required <p>Returns:</p> Type Description <code>ForestContainer</code> <p>In-memory <code>ForestContainer</code> python object, created from JSON string</p>"},{"location":"python_docs/demo/index.html","title":"StochTree Python API Demo","text":"<p>Overview of the <code>stochtree</code> python library's functionality</p>"},{"location":"python_docs/demo/causal_inference.html","title":"Causal Inference Demo Notebook","text":"<p>Load necessary libraries</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom stochtree import BCFModel\nfrom sklearn.model_selection import train_test_split\n</pre> import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from stochtree import BCFModel from sklearn.model_selection import train_test_split <p>Generate sample data</p> In\u00a0[2]: Copied! <pre># RNG\nrng = np.random.default_rng()\n\n# Generate covariates and basis\nn = 1000\np_X = 5\nX = rng.uniform(0, 1, (n, p_X))\npi_X = 0.25 + 0.5*X[:,0]\nZ = rng.binomial(1, pi_X, n).astype(float)\n\n# Define the outcome mean functions (prognostic and treatment effects)\nmu_X = pi_X*5 + 2*X[:,2]\ntau_X = (X[:,1]*2 - 1)\n\n# Generate outcome\nepsilon = rng.normal(0, 1, n)\ny = mu_X + tau_X*Z + epsilon\n</pre> # RNG rng = np.random.default_rng()  # Generate covariates and basis n = 1000 p_X = 5 X = rng.uniform(0, 1, (n, p_X)) pi_X = 0.25 + 0.5*X[:,0] Z = rng.binomial(1, pi_X, n).astype(float)  # Define the outcome mean functions (prognostic and treatment effects) mu_X = pi_X*5 + 2*X[:,2] tau_X = (X[:,1]*2 - 1)  # Generate outcome epsilon = rng.normal(0, 1, n) y = mu_X + tau_X*Z + epsilon <p>Test-train split</p> In\u00a0[3]: Copied! <pre>sample_inds = np.arange(n)\ntrain_inds, test_inds = train_test_split(sample_inds, test_size=0.5)\nX_train = X[train_inds,:]\nX_test = X[test_inds,:]\nZ_train = Z[train_inds]\nZ_test = Z[test_inds]\ny_train = y[train_inds]\ny_test = y[test_inds]\npi_train = pi_X[train_inds]\npi_test = pi_X[test_inds]\nmu_train = mu_X[train_inds]\nmu_test = mu_X[test_inds]\ntau_train = tau_X[train_inds]\ntau_test = tau_X[test_inds]\n</pre> sample_inds = np.arange(n) train_inds, test_inds = train_test_split(sample_inds, test_size=0.5) X_train = X[train_inds,:] X_test = X[test_inds,:] Z_train = Z[train_inds] Z_test = Z[test_inds] y_train = y[train_inds] y_test = y[test_inds] pi_train = pi_X[train_inds] pi_test = pi_X[test_inds] mu_train = mu_X[train_inds] mu_test = mu_X[test_inds] tau_train = tau_X[train_inds] tau_test = tau_X[test_inds] <p>Run BCF</p> In\u00a0[4]: Copied! <pre>bcf_model = BCFModel()\nbcf_model.sample(X_train, Z_train, y_train, pi_train, X_test, Z_test, pi_test, num_gfr=10, num_mcmc=100, params={\"keep_every\": 5})\n</pre> bcf_model = BCFModel() bcf_model.sample(X_train, Z_train, y_train, pi_train, X_test, Z_test, pi_test, num_gfr=10, num_mcmc=100, params={\"keep_every\": 5}) <p>Inspect the MCMC (BART) samples</p> In\u00a0[5]: Copied! <pre>forest_preds_y_mcmc = bcf_model.y_hat_test\ny_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True)\ny_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"])\nsns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\")\nplt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3)))\nplt.show()\n</pre> forest_preds_y_mcmc = bcf_model.y_hat_test y_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True) y_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"]) sns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\") plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3))) plt.show() In\u00a0[6]: Copied! <pre>forest_preds_tau_mcmc = bcf_model.tau_hat_test\ntau_avg_mcmc = np.squeeze(forest_preds_tau_mcmc).mean(axis = 1, keepdims = True)\ntau_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(tau_test,1), tau_avg_mcmc), axis = 1), columns=[\"True tau\", \"Average estimated tau\"])\nsns.scatterplot(data=tau_df_mcmc, x=\"True tau\", y=\"Average estimated tau\")\nplt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3)))\nplt.show()\n</pre> forest_preds_tau_mcmc = bcf_model.tau_hat_test tau_avg_mcmc = np.squeeze(forest_preds_tau_mcmc).mean(axis = 1, keepdims = True) tau_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(tau_test,1), tau_avg_mcmc), axis = 1), columns=[\"True tau\", \"Average estimated tau\"]) sns.scatterplot(data=tau_df_mcmc, x=\"True tau\", y=\"Average estimated tau\") plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3))) plt.show() In\u00a0[7]: Copied! <pre>forest_preds_mu_mcmc = bcf_model.mu_hat_test\nmu_avg_mcmc = np.squeeze(forest_preds_mu_mcmc).mean(axis = 1, keepdims = True)\nmu_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(mu_test,1), mu_avg_mcmc), axis = 1), columns=[\"True mu\", \"Average estimated mu\"])\nsns.scatterplot(data=mu_df_mcmc, x=\"True mu\", y=\"Average estimated mu\")\nplt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3)))\nplt.show()\n</pre> forest_preds_mu_mcmc = bcf_model.mu_hat_test mu_avg_mcmc = np.squeeze(forest_preds_mu_mcmc).mean(axis = 1, keepdims = True) mu_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(mu_test,1), mu_avg_mcmc), axis = 1), columns=[\"True mu\", \"Average estimated mu\"]) sns.scatterplot(data=mu_df_mcmc, x=\"True mu\", y=\"Average estimated mu\") plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3))) plt.show() In\u00a0[8]: Copied! <pre>sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bcf_model.num_samples),axis=1), np.expand_dims(bcf_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"])\nsns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\")\nplt.show()\n</pre> sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bcf_model.num_samples),axis=1), np.expand_dims(bcf_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"]) sns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\") plt.show() In\u00a0[9]: Copied! <pre>b_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bcf_model.num_samples),axis=1), np.expand_dims(bcf_model.b0_samples,axis=1), np.expand_dims(bcf_model.b1_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Beta_0\", \"Beta_1\"])\nsns.scatterplot(data=b_df_mcmc, x=\"Sample\", y=\"Beta_0\")\nsns.scatterplot(data=b_df_mcmc, x=\"Sample\", y=\"Beta_1\")\nplt.show()\n</pre> b_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bcf_model.num_samples),axis=1), np.expand_dims(bcf_model.b0_samples,axis=1), np.expand_dims(bcf_model.b1_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Beta_0\", \"Beta_1\"]) sns.scatterplot(data=b_df_mcmc, x=\"Sample\", y=\"Beta_0\") sns.scatterplot(data=b_df_mcmc, x=\"Sample\", y=\"Beta_1\") plt.show()"},{"location":"python_docs/demo/causal_inference.html#causal-inference-demo-notebook","title":"Causal Inference Demo Notebook\u00b6","text":""},{"location":"python_docs/demo/supervised_learning.html","title":"Supervised Learning Demo Notebook","text":"<p>Load necessary libraries</p> In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom stochtree import BARTModel\nfrom sklearn.model_selection import train_test_split\n</pre> import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from stochtree import BARTModel from sklearn.model_selection import train_test_split <p>Generate sample data</p> In\u00a0[2]: Copied! <pre># RNG\nrandom_seed = 1234\nrng = np.random.default_rng(random_seed)\n\n# Generate covariates and basis\nn = 1000\np_X = 10\np_W = 1\nX = rng.uniform(0, 1, (n, p_X))\nW = rng.uniform(0, 1, (n, p_W))\n\n# Define the outcome mean function\ndef outcome_mean(X, W):\n    return np.where(\n        (X[:,0] &gt;= 0.0) &amp; (X[:,0] &lt; 0.25), -7.5 * W[:,0], \n        np.where(\n            (X[:,0] &gt;= 0.25) &amp; (X[:,0] &lt; 0.5), -2.5 * W[:,0], \n            np.where(\n                (X[:,0] &gt;= 0.5) &amp; (X[:,0] &lt; 0.75), 2.5 * W[:,0], \n                7.5 * W[:,0]\n            )\n        )\n    )\n\n# Generate outcome\nepsilon = rng.normal(0, 1, n)\ny = outcome_mean(X, W) + epsilon\n\n# Standardize outcome\ny_bar = np.mean(y)\ny_std = np.std(y)\nresid = (y-y_bar)/y_std\n</pre> # RNG random_seed = 1234 rng = np.random.default_rng(random_seed)  # Generate covariates and basis n = 1000 p_X = 10 p_W = 1 X = rng.uniform(0, 1, (n, p_X)) W = rng.uniform(0, 1, (n, p_W))  # Define the outcome mean function def outcome_mean(X, W):     return np.where(         (X[:,0] &gt;= 0.0) &amp; (X[:,0] &lt; 0.25), -7.5 * W[:,0],          np.where(             (X[:,0] &gt;= 0.25) &amp; (X[:,0] &lt; 0.5), -2.5 * W[:,0],              np.where(                 (X[:,0] &gt;= 0.5) &amp; (X[:,0] &lt; 0.75), 2.5 * W[:,0],                  7.5 * W[:,0]             )         )     )  # Generate outcome epsilon = rng.normal(0, 1, n) y = outcome_mean(X, W) + epsilon  # Standardize outcome y_bar = np.mean(y) y_std = np.std(y) resid = (y-y_bar)/y_std <p>Test-train split</p> In\u00a0[3]: Copied! <pre>sample_inds = np.arange(n)\ntrain_inds, test_inds = train_test_split(sample_inds, test_size=0.5)\nX_train = X[train_inds,:]\nX_test = X[test_inds,:]\nbasis_train = W[train_inds,:]\nbasis_test = W[test_inds,:]\ny_train = y[train_inds]\ny_test = y[test_inds]\n</pre> sample_inds = np.arange(n) train_inds, test_inds = train_test_split(sample_inds, test_size=0.5) X_train = X[train_inds,:] X_test = X[test_inds,:] basis_train = W[train_inds,:] basis_test = W[test_inds,:] y_train = y[train_inds] y_test = y[test_inds] <p>Run BART</p> In\u00a0[4]: Copied! <pre>bart_model = BARTModel()\nparam_dict = {\"num_chains\": 3}\nbart_model.sample(X_train=X_train, y_train=y_train, basis_train=basis_train, X_test=X_test, basis_test=basis_test, num_gfr=10, num_mcmc=100, params=param_dict)\n</pre> bart_model = BARTModel() param_dict = {\"num_chains\": 3} bart_model.sample(X_train=X_train, y_train=y_train, basis_train=basis_train, X_test=X_test, basis_test=basis_test, num_gfr=10, num_mcmc=100, params=param_dict) <p>Inspect the MCMC (BART) samples</p> In\u00a0[5]: Copied! <pre>forest_preds_y_mcmc = bart_model.y_hat_test\ny_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True)\ny_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"])\nsns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\")\nplt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3)))\nplt.show()\n</pre> forest_preds_y_mcmc = bart_model.y_hat_test y_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True) y_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"]) sns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\") plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3))) plt.show() In\u00a0[6]: Copied! <pre>sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bart_model.num_samples),axis=1), np.expand_dims(bart_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"])\nsns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\")\nplt.show()\n</pre> sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bart_model.num_samples),axis=1), np.expand_dims(bart_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"]) sns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\") plt.show() <p>Compute the test set RMSE</p> In\u00a0[7]: Copied! <pre>np.sqrt(np.mean(np.power(y_test - np.squeeze(y_avg_mcmc),2)))\n</pre> np.sqrt(np.mean(np.power(y_test - np.squeeze(y_avg_mcmc),2))) Out[7]: <pre>np.float64(1.1027425908753832)</pre> <p>Run BART</p> In\u00a0[8]: Copied! <pre>bart_model = BARTModel()\nX_train_aug = np.c_[X_train, basis_train]\nX_test_aug = np.c_[X_test, basis_test]\nbart_model.sample(X_train=X_train_aug, y_train=y_train, X_test=X_test_aug, num_gfr=10, num_mcmc=100)\n</pre> bart_model = BARTModel() X_train_aug = np.c_[X_train, basis_train] X_test_aug = np.c_[X_test, basis_test] bart_model.sample(X_train=X_train_aug, y_train=y_train, X_test=X_test_aug, num_gfr=10, num_mcmc=100) <p>Inspect the MCMC (BART) samples</p> In\u00a0[9]: Copied! <pre>forest_preds_y_mcmc = bart_model.y_hat_test\ny_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True)\ny_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"])\nsns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\")\nplt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3)))\nplt.show()\n</pre> forest_preds_y_mcmc = bart_model.y_hat_test y_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True) y_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"]) sns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\") plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3))) plt.show() In\u00a0[10]: Copied! <pre>sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bart_model.num_samples),axis=1), np.expand_dims(bart_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"])\nsns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\")\nplt.show()\n</pre> sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bart_model.num_samples),axis=1), np.expand_dims(bart_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"]) sns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\") plt.show() <p>Compute the test set RMSE</p> In\u00a0[11]: Copied! <pre>np.sqrt(np.mean(np.power(y_test - np.squeeze(y_avg_mcmc),2)))\n</pre> np.sqrt(np.mean(np.power(y_test - np.squeeze(y_avg_mcmc),2))) Out[11]: <pre>np.float64(1.2588677993651116)</pre> <p>Run BART</p> In\u00a0[12]: Copied! <pre>bart_model = BARTModel()\nbart_model.sample(X_train=X_train, y_train=y_train, X_test=X_test, num_gfr=10, num_mcmc=100)\n</pre> bart_model = BARTModel() bart_model.sample(X_train=X_train, y_train=y_train, X_test=X_test, num_gfr=10, num_mcmc=100) <p>Inspect the MCMC (BART) samples</p> In\u00a0[13]: Copied! <pre>forest_preds_y_mcmc = bart_model.y_hat_test\ny_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True)\ny_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"])\nsns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\")\nplt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3)))\nplt.show()\n</pre> forest_preds_y_mcmc = bart_model.y_hat_test y_avg_mcmc = np.squeeze(forest_preds_y_mcmc).mean(axis = 1, keepdims = True) y_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(y_test,1), y_avg_mcmc), axis = 1), columns=[\"True outcome\", \"Average estimated outcome\"]) sns.scatterplot(data=y_df_mcmc, x=\"Average estimated outcome\", y=\"True outcome\") plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (3,3))) plt.show() In\u00a0[14]: Copied! <pre>sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bart_model.num_samples),axis=1), np.expand_dims(bart_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"])\nsns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\")\nplt.show()\n</pre> sigma_df_mcmc = pd.DataFrame(np.concatenate((np.expand_dims(np.arange(bart_model.num_samples),axis=1), np.expand_dims(bart_model.global_var_samples,axis=1)), axis = 1), columns=[\"Sample\", \"Sigma\"]) sns.scatterplot(data=sigma_df_mcmc, x=\"Sample\", y=\"Sigma\") plt.show() <p>Compute the test set RMSE</p> In\u00a0[15]: Copied! <pre>np.sqrt(np.mean(np.power(y_test - np.squeeze(y_avg_mcmc),2)))\n</pre> np.sqrt(np.mean(np.power(y_test - np.squeeze(y_avg_mcmc),2))) Out[15]: <pre>np.float64(2.0511189627532773)</pre>"},{"location":"python_docs/demo/supervised_learning.html#supervised-learning-demo-notebook","title":"Supervised Learning Demo Notebook\u00b6","text":""},{"location":"python_docs/demo/supervised_learning.html#demo-1-using-w-in-a-linear-leaf-regression","title":"Demo 1: Using <code>W</code> in a linear leaf regression\u00b6","text":""},{"location":"python_docs/demo/supervised_learning.html#demo-2-including-w-as-a-covariate-in-the-standard-constant-leaf-bart-model","title":"Demo 2: Including <code>W</code> as a covariate in the standard \"constant leaf\" BART model\u00b6","text":""},{"location":"python_docs/demo/supervised_learning.html#demo-3-omitting-w-entirely","title":"Demo 3: Omitting <code>W</code> entirely\u00b6","text":""}]}